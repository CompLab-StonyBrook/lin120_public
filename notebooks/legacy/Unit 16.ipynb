{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing the Word Completion Model: String Slices and Frequencies\n",
    "\n",
    "You can now write a simple program for finding all possible word completions using either `str.startswith` or a custom function `startswith` that uses a while loop to compare letters one-by-one.\n",
    "This unit shows you one more general purpose alternative to `str.starswith`, and then we will add frequency information to get only the most likely word completion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting strings into slices\n",
    "\n",
    "### Use for word prediction\n",
    "\n",
    "In the previous unit, we described a specific way of manually checking whether `long_string` is a possible completion of `short_string`.\n",
    "The procedure broke down into the following steps:\n",
    "\n",
    "1. Determine the length of `short_string`.\n",
    "1. Use this to compute the positions 1, 2, 3, ..., n where `short_string` and `long_string` must be identical.\n",
    "1. Check for each position that identity holds.\n",
    "\n",
    "But instead we could have also done the following.\n",
    "\n",
    "1. Determine the length of `short_string`.\n",
    "1. Truncate `long_string` so that it has the same length as `short_string`.\n",
    "   That is to say, cut off the part at the end that makes `long_string` longer than `short_string.\n",
    "1. Test if `short_string` and the truncated version of `long_string` are identical.\n",
    "   If so, `long_string` is a possible completion of `short_string.\n",
    "   \n",
    "Let's illustrate this idea with an example first.\n",
    "Is `yesty` a possible completion of `yes`?\n",
    "The answer is obviously yes, but here are the specific steps that derive this conclusion:\n",
    "\n",
    "1. The length of `yes` is 3.\n",
    "1. If we truncate `yesty` to a length of 3, we get `yes`.\n",
    "1. Since `yes == yes` is `True`, we conclude that `yesty` is a possible completion of `yes`.\n",
    "\n",
    "Python makes it very easy to truncate strings to a specific length.\n",
    "The key tool for this is **slices**.\n",
    "The specification of a slice is similar to how we specify positions in a string.\n",
    "Instead of writing, say, `\"yesty\"[0]` to get the first letter of the string `\"yesty\"`, we write `\"yesty[0:3]\"` to get the substring that spans from position 0 to position 3.\n",
    "So the general syntax is `\"string\"[start_position:end_position]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getting the substring between positions 0 and 3\n",
    "print(\"yesty\"[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# truncating yester to the length of yes\n",
    "print(\"yesty\"[0:len(\"yes\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the start position of a slice does not need to be 0, we can also pick other positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"yesty\"[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the special case where the start position is 0, it can be completely omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"yesty\"[0:3])\n",
    "print(\"yesty\"[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may remember this notation from earlier units when we used commands like `hamlet[:100]` to look at the first 100 word tokens of *Hamlet*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "For each one of the following commands, add a comment that explains what it does.\n",
    "If a command raises an error, comment it out and explain what causes the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"yesty\"[:len(\"yes\")])\n",
    "# your comment:\n",
    "\n",
    "print(\"yesty\"[:len(\"yesty\")])\n",
    "# your comment:\n",
    "\n",
    "print(\"yesty\"[2:5])\n",
    "# your comment:\n",
    "\n",
    "print(\"yesty\"[2:])\n",
    "# your comment:\n",
    "\n",
    "print(\"yesty\"[:])\n",
    "# your comment:\n",
    "\n",
    "print(\"yesty\"[])\n",
    "# your comment:\n",
    "\n",
    "print(\"yesty\"[4:2])\n",
    "# your comment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With slices, there is yet another way of implementing the `complete_word` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "The implementation of `complete_word` below now uses slices.\n",
    "Add a comment to each line that explains what this line does.\n",
    "Pay particular attention to how the slice is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complete_word(string, dictionary):\n",
    "    completions = []\n",
    "    for word in dictionary:\n",
    "        if word[:len(string)] == string:\n",
    "            list.append(completions, word)\n",
    "    return completions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evidence that this version of `complete_word` computes the same output as previous implementations, you can look at the output for the commands below and compare it to the output we got in the previous unit.\n",
    "Make sure you run the first cell, though, so that `dictionary` is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as text:\n",
    "        return text.read()\n",
    "\n",
    "# download the file\n",
    "url = \"https://raw.githubusercontent.com/dwyl/english-words/master/words.txt\"\n",
    "urllib.request.urlretrieve(url, \"words.txt\")\n",
    "dict_string = read_file(\"words.txt\")\n",
    "\n",
    "# tokenize dict_string;\n",
    "# remember that each word is on its own line, so [^\\n]+ does the trick\n",
    "dictionary = re.findall(r\"[^\\n]+\", dict_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_word(\"excite\", dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_word(\"yes\", dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An important note on slices and positions\n",
    "\n",
    "There is one thing about slices that might be a bit confusing, and that's how the end position is interpreted.\n",
    "You might think that something like `\"yesty\"[0:3]` means \"print the characters at positions 0, 1, 2, and 3\".\n",
    "But that's not what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Let's compare positions to slices:\")\n",
    "teststring = \"yesty\"\n",
    "for pos in [0,1,2,3]:\n",
    "    print(\"At position\", pos, \"of\", teststring, \"we have the character\", teststring[pos])\n",
    "    \n",
    "for pos in [0,1,2,3]:\n",
    "    print(\"But the slice of\", teststring, \"from 0 to\", pos, \"is\", teststring[0:pos])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand what's going on here, we have to think a bit more carefully about how Python handle's positions in a string.\n",
    "As far as Python is concerned, a string looks similar to the following thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list(enumerate(\"yesty\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format makes it very clear how positions correspond to specific characters in the string.\n",
    "A pair `(p, \"c\")` means that at position `p` in the string we see character `c`.\n",
    "So far so good, this is exactly what we expect given what we have learned about positions so far.\n",
    "But why, then, does `\"yesty\"[0:3]` give us `yes` rather than `yest`?\n",
    "\n",
    "Without going too much into technical details, this is because slices have a specific interpretation.\n",
    "Suppose that we look at the string `\"yesty\"` as a list of pairs as in the output above.\n",
    "Then the command `\"yesty\"[0:3]` tells Python to start at position `0` and keep moving right until it sees the number `3`.\n",
    "The characters it has seen along the way are combined into a string.\n",
    "Here is how this logic works for `\"yesty\"[0:3]`:\n",
    "\n",
    "1. We start at position 0.\n",
    "1. We take one step to the right and see a `y`.\n",
    "1. We take another step to the right and see the position 1.\n",
    "   We don't care about this position, so we move on.\n",
    "1. We take another step to the right and see an `e`.\n",
    "   We add this to the `y` that we saw before, yielding `ye`.\n",
    "1. We take another step to the right and see the position 2.\n",
    "   We do not care about this position either, so we move on.\n",
    "1. We take another step to the right and see an `s`.\n",
    "   We add that to the already built string `ye` to get `yes`.\n",
    "1. We take another step to the right and see the position 3.\n",
    "   This is where we have to stop, so we call it a day and return the string built so far: `yes`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at slicing from this perspective also explains a few other things that are pretty confusing at first.\n",
    "For example, consider what happens when we give Python a position that does not exist in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"yesty\"[len(\"yesty\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `\"yesty\"` has a length of 5, there are 5 positions: 0, 1, 2, 3, and 4.\n",
    "But `\"yesty\"[len(\"yesty\")]` is the same as `\"yesty\"[5]`, and there is no position 5 in the string.\n",
    "So we get an `IndexError`, telling us that the positoin we used is not available.\n",
    "\n",
    "Now let's contrast that with slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"yesty\"[:len(\"yesty\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are telling Python to give us the slice from 0 to 5 in `\"yesty\"`.\n",
    "Instead of an `IndexError`, we get the entire string.\n",
    "Whenever the end point of a slice is greater than the last available position, Python just uses the end of the string as the final position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"yesty\"[4])\n",
    "print(\"yesty\"[:4])\n",
    "print(\"yesty\"[:5])\n",
    "print(\"yesty\"[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"yesty\"[2:4])\n",
    "print(\"yesty\"[2:5])\n",
    "print(\"yesty\"[2:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why can we go beyond the last position for slices, but not for individual elements?\n",
    "If you think about how slices are computed, it makes sense that we can get an output even if the end point is beyond the possible range.\n",
    "We simply build the string as far as possible and then terminate when there are no more positions to look at.\n",
    "But what is Python to do if we want `\"yesty\"[5]` and there simply is nothing at this position because the last position is 4?\n",
    "It could give us the last character `y` as a backup, but this can introduce all kinds of unintended bugs.\n",
    "Python's philosophy in this case is to say \"Dude, I think you made a mistake here, please go ahead and fix it because I don't know what to do with this\".\n",
    "Whereas in the case of slices, there is a safe fallback: \"Well, I guess he just wants me to go as far right as possible in this string. Alright, no harm in doing that.\"\n",
    "\n",
    "The bottom-line: for individual elements we can only use the available positions, but for slides we can go beyond the right edge of a string without any major problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "In an earlier exercise, you saw that `\"yesty\"[4:2]` does not return anything.\n",
    "That is actually not quite true.\n",
    "It does return something, the *empty string* `\"\"`.\n",
    "This is a string that contains nothing at all.\n",
    "It's length is 0, and it contains no positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The length of the empty string:\")\n",
    "print(len(\"\"))\n",
    "print(\"And its list of positions:\")\n",
    "print(list(enumerate(\"\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the intuition about how slices work, can you explain why `\"yesty\"[4:2]` returns a string, but the string it empty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*put your explanation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggesting only common completions\n",
    "\n",
    "Alright, we now have three different ways of implementing the same idea: iterating over a dictionary with a `for`-loop to find possible completions.\n",
    "So now we will try to restrict it to the most likely completions.\n",
    "Note that we are still using a unigram model, so the most likely completions are simply those among the possible completions with the highest frequency.\n",
    "As we will see, this doesn't work too well in practice, so we'll move to bigrams and trigrams in the next unit to better account for context.\n",
    "\n",
    "### Getting frequency information\n",
    "\n",
    "Adding frequency information is fairly easy.\n",
    "All we need is a bunch of corpora from which we have already constructed counters that tell us for each word type how many tokens it has.\n",
    "Since we have been doing quite a lot of corpus-based work in the last few units, we have all the code ready for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# we first define custom functions for all individual steps\n",
    "\n",
    "def get_file(text):\n",
    "    if text == \"hamlet\":\n",
    "        urllib.request.urlretrieve(\"http://www.gutenberg.org/cache/epub/1524/pg1524.html\", \"hamlet.txt\")\n",
    "    if text == \"faustus\":\n",
    "        urllib.request.urlretrieve(\"http://www.gutenberg.org/cache/epub/811/pg811.txt\", \"faustus.txt\")\n",
    "    if text == \"johncarter\":\n",
    "        urllib.request.urlretrieve(\"http://www.gutenberg.org/cache/epub/62/pg62.txt\", \"johncarter.txt\")\n",
    "        \n",
    "def read_file(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as text:\n",
    "        return text.read()\n",
    "    \n",
    "def delete_before_line(string, line):\n",
    "    return str.split(string, \"\\n\", line)[-1]\n",
    "\n",
    "def delete_after_line(string, line):\n",
    "    return str.join(\"\\n\", str.split(string, \"\\n\")[:line+1])\n",
    "\n",
    "def hamlet_cleaner(text):\n",
    "    # 0. delete unwanted lines\n",
    "    text = delete_after_line(delete_before_line(text, 366), 10928)\n",
    "    # 1. remove all headers, i.e. lines starting with <h1, <h2, <h3, and so on\n",
    "    text = re.sub(r\"<h[0-9].*\", r\"\", text)\n",
    "    # 2. remove speaker information, i.e. lines of the form <p id=\"id012345789\"...<br/>\n",
    "    text = re.sub(r'<p id=\"id[0-9]*\">[^<]*<br/>', r\"\", text)\n",
    "    # 3. remove html tags, i.e. anything of the form <...>\n",
    "    text = re.sub(r\"<[^>]*>\", r\"\", text)\n",
    "    # 4. remove anything after [ or before ] on a line (this takes care of stage descriptions)\n",
    "    text = re.sub(r\"\\[[^\\]\\n]*\", r\"\", text)\n",
    "    text = re.sub(r\"[^\\[\\n]*\\]\", r\"\", text)\n",
    "    return text\n",
    "\n",
    "def faustus_cleaner(text):\n",
    "    # 0. delete unwanted lines\n",
    "    text = delete_after_line(delete_before_line(text, 139), 2854)\n",
    "    # 1. remove stage information\n",
    "    #    (anything after 10 spaces)\n",
    "    text = re.sub(r\"(\\s){10}[^\\n]*\", r\"\", text)\n",
    "    # 2. remove speaker information\n",
    "    #    (any word in upper caps followed by space or dot)\n",
    "    text = re.sub(r\"[A-Z]{2,}[\\s\\.]\", r\"\", text)\n",
    "    # 3. remove anything between square brackets (this takes care of footnote markers)\n",
    "    text = re.sub(r\"\\[[^\\]]*\\]\", r\"\", text)\n",
    "    return text\n",
    "\n",
    "def johncarter_cleaner(text):\n",
    "    # 0. delete unwanted lines\n",
    "    text = delete_after_line(delete_before_line(text, 234), 6940)\n",
    "    # 1. delete CHAPTER I\n",
    "    # (must be done like this because Roman 1 looks like English I)\n",
    "    text = re.sub(\"CHAPTER I\", \"\", text)\n",
    "    # 2. remove any word in upper caps that is longer than 1 character\n",
    "    text = re.sub(r\"[A-Z]{2,}\", r\"\", text)\n",
    "    # 3. remove anything after [ or before ] on a line\n",
    "    text = re.sub(r\"\\[[^\\]\\n]*\", r\"\", text)\n",
    "    text = re.sub(r\"[^\\[\\n]*\\]\", r\"\", text)\n",
    "    return text\n",
    "\n",
    "def tokenize(string):\n",
    "    return re.findall(r\"\\w+\", string)\n",
    "\n",
    "def count(token_list):\n",
    "    return Counter(token_list)\n",
    "\n",
    "\n",
    "# and now we have two functions that use all the previous functions\n",
    "# to do all the necessary work for us\n",
    "def get_and_clean(text):\n",
    "    get_file(text)\n",
    "    string = read_file(text + \".txt\")\n",
    "    string = str.lower(string)\n",
    "    # file-specific cleaning steps\n",
    "    if text == \"hamlet\":\n",
    "        return hamlet_cleaner(string)\n",
    "    if text == \"faustus\":\n",
    "        return faustus_cleaner(string)\n",
    "    if text == \"johncarter\":\n",
    "        return johncarter_cleaner(string)\n",
    "\n",
    "def tokenize_and_count(string):\n",
    "    return (count(tokenize(string)))\n",
    "\n",
    "# and finally we get to run all the code\n",
    "hamlet = tokenize_and_count(get_and_clean(\"hamlet\"))\n",
    "faustus = tokenize_and_count(get_and_clean(\"faustus\"))\n",
    "johncarter = tokenize_and_count(get_and_clean(\"johncarter\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can use word counts from *Hamlet*, *Dr. Faustus*, and *The Princess of Mars* to pick out the most frequent word completions.\n",
    "Note that those are not the most realistic counts for daily usage since nobody writes their emails and text messages like a Victorian play or a pulpy sci-fi novel.\n",
    "But it's better than nothing - and realistic corpora are rare anyways, many models are still trained on samples from the *Wall Street Journal*, which isn't exactly known for its casual prose.\n",
    "\n",
    "In addition to those three corpora, we can also treat our dictionary as a corpus where every word type has exactly one token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download the dictionary file\n",
    "url = \"https://raw.githubusercontent.com/dwyl/english-words/master/words.txt\"\n",
    "urllib.request.urlretrieve(url, \"words.txt\")\n",
    "dict_string = read_file(\"words.txt\")\n",
    "\n",
    "# tokenize dict_string;\n",
    "# remember that each word is on its own line, so [^\\n]+ does the trick\n",
    "dictionary = re.findall(r\"[^\\n]+\", dict_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can combine all these counters into a single counter.\n",
    "Python makes this very easy for us, as we can just use `+` to add two counters.\n",
    "Adding two counters means the following:\n",
    "\n",
    "1. If a word type exists in both counters, we add up the two token counts.\n",
    "1. If a word only exists in one counter, we add it to their combination with its current count.\n",
    "\n",
    "Check out the cell below for an illustrative toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counterA = Counter([\"a\", \"a\", \"a\", \"b\", \"b\", \"c\"])\n",
    "counterB = Counter([\"a\", \"a\", \"a\", \"b\", \"b\", \"d\"])\n",
    "counterAB = counterA + counterB\n",
    "\n",
    "print(counterA)\n",
    "print(counterB)\n",
    "print(counterAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can construct a new counter `wordcounts` by turning `dictionary` into a counter and combining it with the counters `hamlet`, `faustus`, and `johncarter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make dictionary a counter\n",
    "dict_counter = Counter(dictionary)\n",
    "# add all the four counters together\n",
    "wordcounts = dict_counter + hamlet + faustus + johncarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A word of advice: don't print `wordcounts`, it's going to be one giant counter (remember, `dictionary` contains over 500,000 different words!).\n",
    "But we can look at the values for some specific words to verify that the combination worked as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's check the values for a few words\n",
    "for word in [\"there\", \"tender\", \"IRS\", \"Microsoft\"]:\n",
    "    print(\"Showing counts for\", word)\n",
    "    # first the individual counters:\n",
    "    print(\"Dictionary:\", dict_counter[word])\n",
    "    print(\"Hamlet:\", hamlet[word])\n",
    "    print(\"Faustus:\", faustus[word])\n",
    "    print(\"Princess of Mars\", johncarter[word])\n",
    "    # and the value for wordcounts should be the sum of the previous four\n",
    "    print(\"Total\", wordcounts[word])\n",
    "    # add a new line at the end\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the most common words using the `Counter.most_common` function that we encountered in an earlier unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(Counter.most_common(wordcounts, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far things have been easy.\n",
    "Now comes the interesting part: using the counter to get the most likely word completions.\n",
    "Before proceeding, think a bit about how you would solve the problem, it is a good test of whether you have learned to combine certain general purpose techniques to produce a specialized solution.\n",
    "\n",
    "Keep thinking...\n",
    "\n",
    "Keep thinking...\n",
    "\n",
    "Keep thinking...\n",
    "\n",
    "Maybe take another few minutes...\n",
    "\n",
    "Alright, here's how we're gonna do it.\n",
    "Maybe your solution is the same.\n",
    "The `Counter.most_common` function tells us the most common words in a counter.\n",
    "We can use this to get the most likely word completions for any string `foo`:\n",
    "\n",
    "1. We use the `Counter.copy` function to make a copy `completion_counter` of the `wordcounts` counter.\n",
    "1. We iterate over the elements of `completion_counter`.\n",
    "   If a given word `bar` is not a possible completion of `foo`, we set its value to 0: `completion_counter[\"bar\"] = 0`.\n",
    "   Otherwise we keep the value as is.\n",
    "1. Once we have checked every word, we use `Counter.most_common(completion_counter, 3)` to get the 3 most likely completions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Implement the procedure above as a custom function `best_completions` that takes two arguments:\n",
    "\n",
    "1. `string` is the word we want to find the best completions for, and\n",
    "1. `frequencies` is a counter.\n",
    "\n",
    "Some of the relevant code has already been added to make your life easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_completions(string, frequencies):\n",
    "    # 1) completion_counter = copy of frequencies\n",
    "    # 2) iterate over completion_counter\n",
    "        # 2.1) test if element is a possible completion of string\n",
    "            # 2.2) if not, set its value to 0\n",
    "    return Counter.most_common(completion_counter, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code on the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(best_completions(\"exc\", wordcounts))\n",
    "# intended output: [('except', 29), ('excellent', 19), ('exclaimed', 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(best_completions(\"ther\", wordcounts))\n",
    "# intended output: [('there', 272), ('therefore', 44), ('thereafter', 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(best_completions(\"is\", wordcounts))\n",
    "# intended output: [('is', 751), ('iss', 8), ('issued', 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, this seems to be working.\n",
    "One minor quibble is that `Counter.most_common` doesn't just give us the word types, but also their counts.\n",
    "So instead of just `[\"except\", \"excellent\", \"exclaimed\"]`, we get `[(\"except\", 29), (\"excellent\", 19), (\"exclaimed\", 10)]`.\n",
    "Elements like `(\"except\", 29)` are called *tuples*.\n",
    "They are very similar to lists, except that one cannot make any changes to them: items canont be altered, added or removed items.\n",
    "But we can reference specific positions of a tuple just like we do for strings and lists, and this allows us to write a custom function that removes the counts and only keeps the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "The relevant code is shown below.\n",
    "Add a comment to each line that explains what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_counts(most_common):\n",
    "    words = []\n",
    "    for entry in most_common:\n",
    "        word = entry[0]\n",
    "        list.append(words, word)\n",
    "    return words\n",
    "\n",
    "def nice_completions(string, counter):\n",
    "    return strip_counts(best_completions(string, counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(nice_completions(\"exc\", wordcounts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(nice_completions(\"ther\", wordcounts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(nice_completions(\"is\", wordcounts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, now we really get a nice list of the most likely completions ordered by frequency in our corpora.\n",
    "Unfortunately our solution has a severe problem that makes it almost useless in the real world: we are using a unigram model, so we assume that the more frequent the word, the more likely it is to be the desired completion for a word.\n",
    "But this is not how language works, what words are possible completions depends a lot on the context in the sentence.\n",
    "\n",
    "For example, suppose the user has already typed *the exc*.\n",
    "Our model offers three completions for *exc*: *except*, *excellent*, and *exclaimed*.\n",
    "But two of those cannot be the intended word.\n",
    "No sentence in English can ever contain the string *the except*, and while *the exclaimed* is possible in phrases like *the exclaimed crossword clue*, it is very unlikely that this is what the user had in mind.\n",
    "It is much more plausible that the user wants to write *the excellent* or *the exciting* or *the exclusive* or *the excruciating*.\n",
    "So we cannot simply always suggest the most frequent words.\n",
    "Instad, we have to suggest the words that are most likely to occur in the current context.\n",
    "This cannot be done with unigrams; we have to move on to bigrams."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
