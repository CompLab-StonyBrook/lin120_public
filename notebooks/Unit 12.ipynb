{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Writing Style with Unigrams\n",
    "\n",
    "After several weeks on chatbots, we have covered a lot of programming techniques that are useful in this area.\n",
    "In order to progress at the same rate as before, we have to move on to new shores.\n",
    "So we are shifting gears and will now spend a few weeks on word-oriented techniques such as stylistic analysis and spell checking.\n",
    "We will start with stylistic analysis first.\n",
    "\n",
    "\n",
    "## Unigrams and n-grams\n",
    "\n",
    "As you probably know from your highschool days, comparing works of fiction can be a very hard and time-consuming task.\n",
    "It would be much nicer if we could just have the computer do all the work for us.\n",
    "But how could that work?\n",
    "\n",
    "One simple idea is that an author's style is represented by which words (s)he uses, and in particular which words (s)he uses most.\n",
    "Words are also known as *unigrams*.\n",
    "This is in contrast to *bigrams*, which consist of two words, *trigrams* (three words), and so on.\n",
    "For instance, the sentence\n",
    "\n",
    "    John likes Mary and Peter\n",
    "    \n",
    "contains the unigrams\n",
    "\n",
    "    John, likes, Mary, and, Peter\n",
    "    \n",
    "the bigrams\n",
    "\n",
    "    John likes, likes Mary, Mary and, and Peter\n",
    "    \n",
    "and the trigrams\n",
    "\n",
    "    John likes Mary, likes Mary and, Mary and Peter\n",
    "    \n",
    "We could also have 4-grams, 5-grams, or 127-grams.\n",
    "Quite generally, a model that is based on words or sequences of words is called an *n-gram model*.\n",
    "So if we want to analyze an author's style in terms of their word usage, we are proposing a unigram model of stylistic analysis.\n",
    "\n",
    "But does a unigram model actually work for comparing writing style?\n",
    "In class we talked about a study that used a unigram model to predict the success of novels.\n",
    "If that is possible, stylistic analysis might be feasible, too.\n",
    "Well, let's put the idea to the test: we will compare three works of fiction comparing this technique:\n",
    "\n",
    "- William Shakespeare's *Hamlet*\n",
    "- Christopher Marlowe's *The Tragical History of Dr. Faustus*\n",
    "- Edgar Rice Burrough's *A Princess of Mars*\n",
    "\n",
    "If we find something interesting, then unigram models might be worthwhile for stylistic analysis after all.\n",
    "\n",
    "A brief remark on those works: The first two are world-famous plays, whereas the third is an early 20th century pulp novel that you might know as the basis for Disney's 2012 box office debacle *John Carter*.\n",
    "Although the movie is better than its reputation, it still doesn't do justice to the book, so give it a read if you are in the mood for a fun science-fantasy read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the files\n",
    "\n",
    "First we need to have the books in some digital format that we can feed into Python.\n",
    "Ideally, we want this to be a plaintext format, i.e. the pure text without any layout information.\n",
    "We do not want a pdf or doc file, as those are much harder to work with.\n",
    "We can use Python to download all the files from [Project Gutenberg](https://www.gutenberg.org/), an online platform that hosts literary works that are no longer under copyright."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the urllib.request library\n",
    "import urllib.request\n",
    "# download Hamlet\n",
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/cache/epub/1524/pg1524.html\", \"hamlet.txt\")\n",
    "# download Faustus\n",
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/cache/epub/811/pg811.txt\", \"faustus.txt\")\n",
    "# donwnload Princess of Mars\n",
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/cache/epub/62/pg62.txt\", \"johncarter.txt\")\n",
    "\n",
    "# wait till you see an output below this cell;\n",
    "# as long as you see an * next to In[], Python is busy downloading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the cell above, you will have three files in the same folder as the notebook:\n",
    "\n",
    "1. `hamlet.txt`\n",
    "1. `faustus.txt`\n",
    "1. `johncarter.txt`\n",
    "\n",
    "As any other `.txt` file you can open them in a text editor, e.g. Notepad.\n",
    "Do that right now, open the files and take a peek as to what they look like.\n",
    "You'll notice that they're full of stuff that isn't part of the books' text itself.\n",
    "This includes copyright disclaimers, footnotes, and HTML tags.\n",
    "HTML tags are the things between pointy brackets, for instance `<p id=\"019253\">` or `</p>` in *Faustus*.\n",
    "Later on, but we will have to get rid of that, but let's hold off on that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, let's look at the code above to see how it works.\n",
    "The `urllib.request` module provides a function `urlretrieve` that takes two strings as arguments.\n",
    "The first one tells us the URL of the file we want to download, and the second one is the filename we want to save it as.\n",
    "\n",
    "```python\n",
    "    urllib.request.urlretrieve(\"url\", \"filename\")\n",
    "```\n",
    "\n",
    "As you can see, downloading files in Python is easypeasy.\n",
    "\n",
    "However, it is somewhat annoying that we have to type `urllib.request.urlretrieve` all the time, that's one really long function name.\n",
    "We can save ourselves some typing by changing the `import` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directly import urlretrieve from the urllib.request library\n",
    "from urllib.request import urlretrieve\n",
    "# download Hamlet\n",
    "urlretrieve(\"http://www.gutenberg.org/cache/epub/1524/pg1524.html\", \"hamlet.txt\")\n",
    "# download Faustus\n",
    "urlretrieve(\"http://www.gutenberg.org/cache/epub/811/pg811.txt\", \"faustus.txt\")\n",
    "# donwnload Princess of Mars\n",
    "urlretrieve(\"http://www.gutenberg.org/cache/epub/62/pg62.txt\", \"johncarter.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we write `import xyz`, the entire module `xyz` is loaded and all its functions `f`, `g`, `h`, and so on become accessible as `xyz.f`, `xyz.g`, `xyz.h`, and so on.\n",
    "But if we only want one specific function `f`, there is an alternative.\n",
    "Instead of `import xyz`, we can write `from xyz import f`.\n",
    "Then we can directly write `f` instead of `xyz.f`.\n",
    "Note that you cannot write `import urllib.request.urlretrieve`, this will not work because only modules can be imported this way, but `urllib.request.urlretrieve` is a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this code won't work\n",
    "import urllib.request.urlretrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let's get back to our files, which are still ildly hanging around on your harddrive.\n",
    "The files won't do us much good unless we can find a way for Python to actually work with them.\n",
    "We have to tell Python to read in each file as a string.\n",
    "While this isn't too difficult, it involves some new commands and concepts that would only be distracting at this point.\n",
    "So instead, I wrote a function below that already does all the work for you.\n",
    "The expansion unit explains in detail how to work with files in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for reading in files as strings\n",
    "def read_file(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as text:\n",
    "        return text.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you run the cell above, the function `read_file` will be available everywhere else in the notebook (if you restart the kernel, Python forgets how the function is defined, so you'll have to execute the cell again).\n",
    "\n",
    "So now we can read in every file as a string and store the string with a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first hamlet\n",
    "hamlet = read_file(\"hamlet.txt\")\n",
    "# then faustus\n",
    "faustus = read_file(\"faustus.txt\")\n",
    "# then johncarter\n",
    "johncarter = read_file(\"johncarter.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the three cells below to see what the first 1000 characters of each string looks like (the meaning of `[:1000]` will be explained soon in one of the next units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hamlet[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "faustus[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "johncarter[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how there are no visible linebreaks, instead we have the special character `\\n`.\n",
    "Those strings are what the text files look like to Python --- quite different from how a text editor displays them from a human.\n",
    "And in the case of `hamlet`, the string is also littered with HTML tags, which provide additional information for web browsers, in particular how to display the text.\n",
    "Whenever you are looking at a website, your browser actually sees a string like the one for `hamlet`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "We now have all the code we need to download the relevant files and read them in as strings, but it's all scattered across the notebook.\n",
    "If you have to restart the kernel, you'll have to execute all those cells again.\n",
    "So let's add a final step for our convenience that does it all at once.\n",
    "And since we might want to be repeat the steps at a latter point, let's pack it all into a function `get_text`.\n",
    "That way, we can run something like `get_text(\"hamlet\")` at any point later on in the notebook to redownload the original version of Hamlet.\n",
    "That will come in mighty handy if we try to clean up the files and one of our clean-up steps accidentally rips out half the text.\n",
    "\n",
    "So your task is to define a custom function `get_text` that satisfies all of the following criteria:\n",
    "\n",
    "1. `get_text` takes a string as its only argument;\n",
    "1. The values for the argument can be `hamlet`, `faustus`, or `johncarter`.\n",
    "1. If a different string is passed as the argument, e.g. `foobar`, the function will behave as if the argument were `hamlet`.\n",
    "1. Based on what argument was provided, the function\n",
    "    1. downloads the correct file (check the beginning of the notebook for the URLs), and\n",
    "    1. reads in the file as a string (copy-paste the relevant code from the `read_text` function).\n",
    "    \n",
    "Make sure that your code works even if this is the first cell in the notebook to be run.\n",
    "So you will also have to add the necessary `import` statement(s) above the function definition.\n",
    "Once the function has been defined, use it to instantiate the variables `hamlet`, `faustus`, and `johncarter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up the files\n",
    "\n",
    "## Analysis\n",
    "\n",
    "Take one more look at the files you downloaded.\n",
    "Scroll up and down to make sure you get a good impression of what the files look like.\n",
    "Pay close attention to anything that you think is not part of the author's actual writing and should be removed.\n",
    "Go ahead, check out the files, I'll wait here in the meantime.\n",
    "\n",
    "Done? Okay, you should have noticed quite a few problems with the files, only some of which we could ever hope to fix by hand.\n",
    "\n",
    "1. While `faustus.txt` and `mars.txt` are fairly easy to read, `hamlet.txt` is cluttered with HTML tags like `<p id=\"id00057\">` and `<br/>`. That's because we downloaded a textfile for `faustus.txt` and `mars.txt`, but an html-file for `hamlet.txt`.\n",
    "\n",
    "1. All files start with information about Project Gutenberg, which we do not want.\n",
    "\n",
    "1. All files have information at the end that is not part of the play. In `hamlet.txt`, it's just a disclaimer that the play is over, `mars.txt` ends with the Project Gutenberg license, and `faustus.txt` is full of footnotes.\n",
    "\n",
    "1. In `faustus.txt`, the text is often interrupted by strings like `[17]`. Those are references to footnotes.\n",
    "\n",
    "1. For the two plays, different formats are used to indicate who is speaking.\n",
    "    - In `hamlet.txt`, names are abbreviated and occur between the markup `<p id=\"id...\">` and `<br/>`.\n",
    "    - In `faustus.txt`, names are fully capitalized.\n",
    "    \n",
    "1. Both plays put stage instructions between square brackets, for example `[Francisco at his post. Enter to him Bernardo.]`.\n",
    "\n",
    "1. In `faustus.txt`, stage instructions are also indicated by indentation.\n",
    "\n",
    "1. In `faustus.txt`, all dialog is indented, but less so than the stage instructions.\n",
    "    \n",
    "1. All three files contain many empty lines.\n",
    "\n",
    "1. Both plays capitalize words at the beginning of a new line.\n",
    "\n",
    "1. In `mars.txt`, Chapters are written in upper caps.\n",
    "\n",
    "Some of them are very problematic for us:\n",
    "\n",
    "- We just want to be able to see which words are used in each play, and how often each word is used.\n",
    "- We do not want extraneous material such as HTML markup, information about Project Gutenberg, or footnotes.\n",
    "- We also do not want to keep track of names if they just indicate who is speaking. That's not part of the play as such.\n",
    "- We should also exclude stage instructions because those do not belong to the literary part of the play either.\n",
    "\n",
    "Fixing all these things by hand would be tons of work.\n",
    "Fortunately, Python can do it all for us with just the right regular expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up step 1: Deleting the start and end\n",
    "\n",
    "The first step is to remove the parts at the beginning and the end that aren't part of the text itself.\n",
    "The easiest way to do this is to delete everything up to or after a given line number.\n",
    "We can find out the relevant line numbers by opening the files we downloaded in a text editor.\n",
    "\n",
    "Let's start with Hamlet.\n",
    "The play doesn't start until the description *SCENE. Elsinore.* on line 366.\n",
    "So we want to delete the first 365 lines.\n",
    "And the non-play part at the end is marked with *The End of Project Gutenberg Etext of Hamlet by Shakespeare* on line 10929.\n",
    "So everything after line 10928 should be deleted, too.\n",
    "\n",
    "For your convenience, I have already written two custom functions `delete_before_line` and `delete_after_line` that handle the deletion.\n",
    "They take two arguments, a string and a line number, and then delete everything before or after that line number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def delete_before_line(string, line):\n",
    "    return str.split(string, \"\\n\", line)[-1]\n",
    "\n",
    "def delete_after_line(string, line):\n",
    "    return str.join(\"\\n\", str.split(string, \"\\n\")[:line+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not need to worry about how these functions work.\n",
    "That is the beauty of functions, you can treat them as blackboxes and do not need to worry about how exactly they do what they are supposed to do.\n",
    "You didn't worry about how `print` or `re.sub` work, and you do not need to worry about how those two functions work.\n",
    "The important thing is that we can use them to clean up our version of *Hamlet*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hamlet_clean = delete_before_line(hamlet, 366)\n",
    "hamlet_clean = delete_after_line(hamlet_clean, 10928)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we can condense the two lines above into just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hamlet_clean = delete_after_line(delete_before_line(hamlet, 366), 10928)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Explain in a step-wise fashion how the single line of code above does the same work as the two lines we had before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*put your explanation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare `hamlet` and `hamlet_clean` to make sure that the deletion has worked correctly.\n",
    "Since we might want to do this with `faustus` and `johncarter`, too, it is once again convenient to define a custome function.\n",
    "This one is different from the ones we have seen so far in that it has no `return` statement, instead it just uses `print` to show a few strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def comparison_print(text1, text2, number, position):\n",
    "    # we compare a given number of characters in text1 and text2;\n",
    "    # either the first n characters, or the last n characters,\n",
    "    # depending on the value of position\n",
    "    if position == \"start\":\n",
    "        print(\"TEXT 1\")\n",
    "        print(text1[:number])\n",
    "        # add a separator in the output\n",
    "        print()\n",
    "        print(\"--------\")\n",
    "        print()\n",
    "        print(\"TEXT 2\")\n",
    "        print(text2[:number])\n",
    "    if position == \"end\":\n",
    "        print(\"TEXT 1\")\n",
    "        print(text1[-number:])\n",
    "        # add a separator in the output\n",
    "        print()\n",
    "        print(\"--------\")\n",
    "        print()\n",
    "        print(\"TEXT 2\")\n",
    "        print(text2[-number:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare the first 500 characters of hamlet and hamlet_clean\n",
    "comparison_print(hamlet, hamlet_clean, 500, \"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare the last 500 characters of hamlet and hamlet_clean\n",
    "comparison_print(hamlet, hamlet_clean, 500, \"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "There is a minor redundancy in `comparison_print`.\n",
    "No matter whether `position == \"start\"` or `position == \"end\"` is true, a separator needs to be inserted between `text1` and `text2`.\n",
    "Right now the separator is specified directly in the function as\n",
    "\n",
    "```python\n",
    "print()\n",
    "print(\"--------\")\n",
    "print()\n",
    "```\n",
    "\n",
    "But maybe we would like to change it in the future, in which case we would have to change it in two places in the function.\n",
    "Fix this issue by defining a custom function `print_separator()` that prints a separator (you can reuse the code above as it is).\n",
    "Then replace the separator code in `comparison_print` by calls to `print_separator()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add your definition of print_separator here,\n",
    "# then modify comparison_print accordingly\n",
    "\n",
    "def comparison_print(text1, text2, number, position):\n",
    "    # we compare a given number of characters in text1 and text2;\n",
    "    # either the first n characters, or the last n characters,\n",
    "    # depending on the value of position\n",
    "    if position == \"start\":\n",
    "        print(\"TEXT 1\")\n",
    "        print(text1[:number])\n",
    "        # add a separator in the output\n",
    "        print()\n",
    "        print(\"--------\")\n",
    "        print()\n",
    "        print(\"TEXT 2\")\n",
    "        print(text2[:number])\n",
    "    if position == \"end\":\n",
    "        print(\"TEXT 1\")\n",
    "        print(text1[-number:])\n",
    "        # add a separator in the output\n",
    "        print()\n",
    "        print(\"--------\")\n",
    "        print()\n",
    "        print(\"TEXT 2\")\n",
    "        print(text2[-number:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let's move on to the remaining two files.\n",
    "In `faustus`, we want to delete the passage *FROM THE QUARTO OF 1616* on line 138 and everything before it.\n",
    "And we also want to get rid of everything after *Terminat hora diem; terminat auctor opus.* on line 2853.\n",
    "In `johncarter`, we can delete everything before *CHAPTER 1* on line 235, and everything after *that I shall soon know* on line 6939."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Similar to `hamlet_clean`, use the functions `delete_after_line` and `delete_before_line` to define new variables `faustus_clean` and `johncarter_clean`.\n",
    "Make sure you pick the line numbers correctly:\n",
    "\n",
    "- A command of the form `delete_before_line(faustus, n)` deletes everything **before** line `n` but not line `n` itself.\n",
    "- A command of the form `delete_after_line(faustus, n)` deletes everything **after** line `n` but not line `n` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up step 2: Regex galore\n",
    "\n",
    "Alright, we have removed some unnecessary lines from the texts, but the remaining lines still contain quite a bit of crud.\n",
    "We will now clean this up with regular expressions.\n",
    "As before, we start with *Hamlet*, although it is probably the hardest case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def hamlet_cleaner(text):\n",
    "    # 1. remove all headers, i.e. lines starting with <h1, <h2, <h3, and so on\n",
    "    text = re.sub(r\"<h[0-9].*\", r\"\", text)\n",
    "    # 2. remove speaker information, i.e. lines of the form <p id=\"id012345789\"...<br/>\n",
    "    text = re.sub(r'<p id=\"id[0-9]*\">[^<]*<br/>', r\"\", text)\n",
    "    # 3. remove html tags, i.e. anything of the form <...>\n",
    "    text = re.sub(r\"<[^>]*>\", r\"\", text)\n",
    "    # 4. remove anything after [ or before ] on a line (this takes care of stage descriptions)\n",
    "    text = re.sub(r\"\\[[^\\]\\n]*\", r\"\", text)\n",
    "    text = re.sub(r\"[^\\[\\n]*\\]\", r\"\", text)\n",
    "    return text\n",
    "\n",
    "# apply all the regular expressions to hamlet\n",
    "hamlet_regexed = hamlet_cleaner(hamlet_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this cell if you want to compare the new version to the previous\n",
    "comparison_print(hamlet_clean, hamlet_regexed, 500, \"start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expressions above aren't exactly for the faint of heart, but at least one of them is fairly easy to figure out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this cell if you want to compare the new version to the previous one\n",
    "comparison_print(hamlet_clean, hamlet_regexed, 500, \"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Explain how the command `re.sub(r\"<h[0-9].*\", r\"\", text)` removes headers from every line in the file.\n",
    "Here are a few examples of what headers look like in HTML:\n",
    "\n",
    "- `<h1>A level-one header</h1>`\n",
    "- `<h2 style=\"color:#069\">A level-two header with additional styling</h2>`\n",
    "- `<h3 class=\"test\">A level-three header belonging to a custom class \"test\"</h3>`\n",
    "- `<h4 class=\"test\" id=\"320\" style=\"color:#069\">A level-four header with class, id, and style specifications</h4>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*put your explanation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, *Hamlet* is now in a workable state.\n",
    "So let's try *Faustus* next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def faustus_cleaner(text):\n",
    "    # 1. remove stage information\n",
    "    #    (anything after 10 spaces)\n",
    "    text = re.sub(r\"(\\s){10}[^\\n]*\", r\"\", text)\n",
    "    # 2. remove speaker information\n",
    "    #    (any word in upper caps followed by space or dot)\n",
    "    text = re.sub(r\"[A-Z]{2,}[\\s\\.]\", r\"\", text)\n",
    "    # 3. remove anything between square brackets (this takes care of footnote markers)\n",
    "    text = re.sub(r\"\\[[^\\]]*\\]\", r\"\", text)\n",
    "    return text\n",
    "    \n",
    "faustus_regexed = faustus_cleaner(faustus_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Explain in a step-wise fashion how `re.sub(r\"\\[[^\\]]*\\]\", r\"\", text)` takes a string of the form `bla bla [ble ble] bli bli [blo blo] blu blu` and reduces it to `bla bla  bli bli  blu blu`.\n",
    "That is to say, how does this regex delete material between square brackets?\n",
    "\n",
    "Keep in mind that `[` and `]` have special meaning in regexes, so `\\[` and `\\]` are used to escape their special meaning and refer to the actual brackets.\n",
    "And remember that `[^abc]` means *match anything except a, b, or c*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*put your description here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again it is advisable to check the output of our cleaning operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this cell if you want to compare the new version to the previous\n",
    "comparison_print(faustus_clean, faustus_regexed, 500, \"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this cell if you want to compare the new version to the previous\n",
    "comparison_print(faustus_clean, faustus_regexed, 500, \"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splendid, our regular expressions are doing an excellent job at automatically ripping out all the stuff we do not want.\n",
    "This leaves us with only one more text, `johncarter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def johncarter_cleaner(text):\n",
    "    # 1. delete CHAPTER I\n",
    "    # (must be done like this because Roman 1 looks like English I)\n",
    "    text = re.sub(\"CHAPTER I\", \"\", text)\n",
    "    # 2. remove any word in upper caps that is longer than 1 character\n",
    "    text = re.sub(r\"[A-Z]{2,}\", r\"\", text)\n",
    "    # 3. remove anything after [ or before ] on a line\n",
    "    text = re.sub(r\"\\[[^\\]\\n]*\", r\"\", text)\n",
    "    text = re.sub(r\"[^\\[\\n]*\\]\", r\"\", text)\n",
    "    return text\n",
    "    \n",
    "johncarter_regexed = johncarter_cleaner(johncarter_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this cell if you want to compare the new version to the previous\n",
    "comparison_print(johncarter_clean, johncarter_regexed, 500, \"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this cell if you want to compare the new version to the previous\n",
    "comparison_print(johncarter_clean, johncarter_regexed, 500, \"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Once again we've reached a milestone, so it's a good idea to collect all the relevant code into a single cell.\n",
    "Write a custom function `get_and_clean` that will\n",
    "\n",
    "- download hamlet, faustus, johncarter, and\n",
    "- read them in a strings, and\n",
    "- clean them up.\n",
    "\n",
    "It is perfectly fine to copy-paste the previous function definitions into the cell below and then just write a custom function that runs them all in the correct order.\n",
    "\n",
    "As before, you should use your new function to instantiate the three variables `hamlet_regexed`, `faustus_regexed`, and `johncarter_regexed`.\n",
    "That way you can always run this cell to automatically repeat all the steps we have taken up to this point in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and counting\n",
    "\n",
    "Now that we have cleaned up the source files, we can finally move on with the analysis.\n",
    "Remember, never rush straight into the analysis, always clean up the data first.\n",
    "Even the best analysis is worthless if it uses bad data.\n",
    "As computer scientists like to say: **garbage in, garbage out**.\n",
    "\n",
    "In our case, the analysis will be fairly straight-forward.\n",
    "We first want to tokenize the texts, which means that we convert them from strings into lists of word tokens.\n",
    "We do this with a regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "tokens_hamlet = re.findall(r\"\\w+\", str.lower(hamlet_regexed))\n",
    "tokens_faustus = re.findall(r\"\\w+\", str.lower(faustus_regexed))\n",
    "tokens_johncarter = re.findall(r\"\\w+\", str.lower(johncarter_regexed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `re.findall` takes two arguments, a regular expression and a string.\n",
    "It then constructs a list that contains all parts of the string that matched the regular expresssion.\n",
    "By using the regex `r\"\\w+\"`, we instruct `re.findall` to look for sequences that consist only of word characters.\n",
    "But that's exactly what a word is, a sequence of word characters!\n",
    "So we are telling `re.findall` to find all words in the string.\n",
    "The cell below illustrates this for a very short string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "test_string = \"FTL is short for faster-than-light; we probably won't ever have space ships capable of FTL-travel.\"\n",
    "tokens = re.findall(r\"\\w+\", str.lower(test_string))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Note that *FTL-travel* is split into two words *FTL* and *travel*, and *won't* is split into *won* and *t*.\n",
    "Explain why this is exactly what we expect given the regex `r\"\\w+\"`.\n",
    "Then fix the code below (it's the same as above) so that the regex also considers hyphens and apostrophes as part of a single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "test_string = \"FTL is short for faster-than-light; we probably won't ever have space ships capable of FTL-travel.\"\n",
    "\n",
    "# tokenize the string\n",
    "tokens = re.findall(r\"\\w+\", str.lower(test_string))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we apply `str.lower` to the string first before it gets fed into `re.findall`.\n",
    "That's because we are tokenizing the string to get word counts, and we want, say, *the* and *The* to be counted as tokens of the same word type *the*.\n",
    "By making everything lowercase, we eliminate these distinctions.\n",
    "However, it may have unintended side effects, like conflating the company name *Google* with the verb *google*.\n",
    "But this is a minor problem compared to capitalization, so we should still get better result with `str.lower` rather than without it.\n",
    "\n",
    "At any rate we now have three variables `tokens_hamlet`, `tokens_faustus`, and `tokens_johncarter` that each store a tokenized version of the three files.\n",
    "The only thing let to do is for us to count the tokens for each word type.\n",
    "Python makes this very easy for us: the `collections` library provides a function `Counter` that does the counting for us.\n",
    "The `Counter` function takes as its only argument a list (like the ones produced by `re.findall` for tokenization).\n",
    "It then converts the list into a *Counter*.\n",
    "Here is what this looks like with our short example string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "test_string = \"FTL is short for faster-than-light; we probably won't ever have space ships capable of FTL-travel.\"\n",
    "\n",
    "# tokenize the string\n",
    "tokens = re.findall(r\"\\w+\", str.lower(test_string))\n",
    "print(\"The list of tokens:\", tokens)\n",
    "\n",
    "# add an empty line\n",
    "print()\n",
    "\n",
    "# and now do the counting\n",
    "counts = Counter(tokens)\n",
    "print(\"Number of tokens for each word type:\", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now let's do the same thing with our three token lists, stored in the variables `tokens_hamlet`, `tokens_faustus`, and `tokens_johncarter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts_hamlet = Counter(tokens_hamlet)\n",
    "counts_faustus = Counter(tokens_faustus)\n",
    "counts_johncarter = Counter(tokens_johncarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Again it would be nice to have a function that does all the previous steps for us in one fell-swoop.\n",
    "Write a custom function `count_tokens` that takes a string as argument and computes its word counts.\n",
    "Then instantiate the variables `counts_hamlet`, `counts_faustus`, and `counts_johncarter` using your custom function.\n",
    "Make sure you also load all required libraries in the cell.\n",
    "\n",
    "Remember, the point of this cell is that when you open the notebook at a later point, you can save some time by just running this cell instead of all the others in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Actually, let's be even lazier and combine the custom functions from the previous exercises.\n",
    "That way, it's enough to just run this cell, skipping all the previous ones.\n",
    "\n",
    "First, copy paste the relevant code into the cell below.\n",
    "Then add a custom function `get_and_count` that satisfies the following criteria:\n",
    "\n",
    "1. `get_and_count` takes a string as its only argument;\n",
    "1. The values for the argument can be `hamlet`, `faustus`, or `johncarter`.\n",
    "1. If a different string is passed as the argument, e.g. `foobar`, the function will behave as if the argument were `hamlet`.\n",
    "1. Based on what argument was provided, the function\n",
    "    1. downloads the correct file, and\n",
    "    1. reads in the file as a string, and\n",
    "    1. tokenizes the string, and\n",
    "    1. counts the tokens.\n",
    "    \n",
    "Then instantiate the variables `counts_hamlet`, `counts_faustus`, and `counts_johncarter` using `get_and_count`.\n",
    "    \n",
    "Remember that you can use a custom function inside the definition of another custom function, so you should be able to write `get_and_count` with a minimal amount of additional code.\n",
    "However, you may have to move some pieces of code from `get_text` into `get_and_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the counts\n",
    "\n",
    "Let's take a quick peak at what the counts looks like for each text.\n",
    "We don't want to do this with something like `print(counts_hamlet)`, because the output would be so large that your browser might actually choke on it (it has happened to me sometimes).\n",
    "Instead, we will look at the 100 most common words.\n",
    "We can do this with the function `Counter.most_common`, which takes two arguments: a Counter, and a positive number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Most common Hamlet words:\", Counter.most_common(counts_hamlet, 100))\n",
    "print()\n",
    "print(\"Most common Faustus words:\", Counter.most_common(counts_faustus, 100))\n",
    "print()\n",
    "print(\"Most common John Carter words:\", Counter.most_common(counts_johncarter, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that doesn't look too bad, but suppose we want to have each entry on its own line, like in a spreadsheet.\n",
    "For this we can use the function `pprint` from the `pprint` library.\n",
    "The name *pprint* is short for *pretty-print*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"Most common Hamlet words:\")\n",
    "pprint(Counter.most_common(counts_hamlet, 100))\n",
    "print()\n",
    "print(\"Most common Faustus words:\")\n",
    "pprint(Counter.most_common(counts_faustus, 100))\n",
    "print()\n",
    "print(\"Most common John Carter words:\")\n",
    "pprint(Counter.most_common(counts_johncarter, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the list format is good for figuring out which specific words are most common, it doesn't tell us much about the frequency distribution in general.\n",
    "Is one of the texts more Zipfian than the others?\n",
    "This is best done with plots.\n",
    "Plotting will be described in an expansion unit, for the main units the plotting code will always be present in the cell already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tell Jupyter to display the plots directly in the browser\n",
    "% matplotlib inline\n",
    "\n",
    "# load the pandas library\n",
    "import pandas\n",
    "\n",
    "def plotting(counts):\n",
    "    counts_sorted = pandas.Series.sort_values(pandas.Series(counts), ascending=False)\n",
    "    counts_sorted.plot(figsize=(15,15))\n",
    "\n",
    "plotting(counts_hamlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "plotting(counts_faustus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "plotting(counts_johncarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs show very nicely that all three texts have a very Zipfian distribution, with a tall neck and a very long tail.\n",
    "However, we also see that *The Princess of Mars* has a harsher shift from neck to tail, with a very slim body, whereas *Hamlet* and *Faustus* are smoother in this area.\n",
    "We can't say much more than that, though, at this point, because any other differences in word frequencies are drowned out by the rather uninformative high-frequency words like *the* and *and*.\n",
    "If we want to dig deeper, we will have to get rid of them.\n",
    "More on how to do that next time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
