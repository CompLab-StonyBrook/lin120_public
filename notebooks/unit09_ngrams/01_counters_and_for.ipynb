{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature analysis with unigrams: Now let's have a little fun\n",
    "\n",
    "The previous notebook showed you how to download and read in files, clean them up, and tokenize them.\n",
    "A tokenized list is nice, but not enough.\n",
    "Slices make it easier for us to compare two versions of the same file, but that's not quite what we want either.\n",
    "In order to carry out a quantitative analysis of each author's writing style, we also need to know how often each word is used.\n",
    "As usual, Python is very kind to us and provides an off-the-shelf solution.\n",
    "\n",
    "But before you proceed, make sure to run the cell below.\n",
    "This will once again read in the cleaned up text files and store them as tokenized lists in the variables `hamlet`, `faustus`, and `mars`.\n",
    "If you get an error, make sure that you did the previous notebook and that this notebook is in a folder containing the files `hamlex_clean.txt`, `faustus_clean.txt`, and `mars_clean.txt` (which should be the case if you did the previous notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(the_string):\n",
    "    \"\"\"Convert string to list of words\"\"\"\n",
    "    return re.findall(r\"\\w+\", the_string)\n",
    "\n",
    "\n",
    "def tokenize_file(the_file):\n",
    "    \"\"\"Read file as string and tokenize it\"\"\"\n",
    "    with open(the_file, mode=\"r\") as text:\n",
    "        return tokenize(text.read())\n",
    "\n",
    "\n",
    "# define a variable for each token list\n",
    "hamlet = tokenize_file(\"hamlet_clean.txt\")\n",
    "faustus = tokenize_file(\"faustus_clean.txt\")\n",
    "mars = tokenize_file(\"mars_clean.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caution.**\n",
    "If you restart the kernel at any point, make sure to run this cell again so that the variables `hamlet`, `faustus`, and `mars` are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting words\n",
    "\n",
    "Python makes it very easy to count how often an element occurs in a list: the `collections` library provides a function `Counter` that does the counting for us.\n",
    "The `Counter` function takes as its only argument a list (like the ones produced by `re.findall` for tokenization).\n",
    "It then converts the list into a *Counter*.\n",
    "Here is what this looks like with a short example string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter  # this allows us to use Counter instead of collections.Counter\n",
    "\n",
    "test_string = \"FTL is short for faster-than-light; we probably won't ever have space ships capable of FTL-travel.\"\n",
    "\n",
    "# tokenize the string\n",
    "tokens = re.findall(r\"\\w+\", str.lower(test_string))\n",
    "print(\"The list of tokens:\", tokens)\n",
    "\n",
    "# add an empty line\n",
    "print()\n",
    "\n",
    "# and now do the counting\n",
    "counts = Counter(tokens)\n",
    "print(\"Number of tokens for each word type:\", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick peak at what the counts looks like for each text.\n",
    "We don't want to do this with something like `print(counts_hamlet)`, because the output would be so large that your browser might actually choke on it (it has happened to me sometimes).\n",
    "Instead, we will look at the 100 most common words.\n",
    "We can do this with the function `Counter.most_common`, which takes two arguments: a Counter, and a positive number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# construct the counters\n",
    "counts_hamlet = Counter(hamlet)\n",
    "counts_faustus = Counter(faustus)\n",
    "counts_mars = Counter(mars)\n",
    "\n",
    "print(\"Most common Hamlet words:\", Counter.most_common(counts_hamlet, 100))\n",
    "print()\n",
    "print(\"Most common Faustus words:\", Counter.most_common(counts_faustus, 100))\n",
    "print()\n",
    "print(\"Most common John Carter words:\", Counter.most_common(counts_mars, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "The code below uses `import collections` instead of `from collections import Counter`.\n",
    "As you can test for yourself, the code now produces various errors.\n",
    "Fix the code so that the cell runs correctly.\n",
    "You must not change the `import` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# construct the counters\n",
    "counts_hamlet = Counter(hamlet)\n",
    "counts_faustus = Counter(faustus)\n",
    "counts_mars = Counter(mars)\n",
    "\n",
    "print(\"Most common Hamlet words:\", Counter.most_common(counts_hamlet, 100))\n",
    "print()\n",
    "print(\"Most common Faustus words:\", Counter.most_common(counts_faustus, 100))\n",
    "print()\n",
    "print(\"Most common John Carter words:\", Counter.most_common(counts_mars, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's output for `Counter.most_common` doesn't look too bad, but it is a bit convoluted.\n",
    "We can use the function `pprint` from the `pprint` library to have each word on its own line.\n",
    "The name *pprint* is short for *pretty-print*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint  # we want to use pprint instead of pprint.pprint\n",
    "from collections import Counter\n",
    "\n",
    "# construct the counters\n",
    "counts_hamlet = Counter(hamlet)\n",
    "counts_faustus = Counter(faustus)\n",
    "counts_mars = Counter(mars)\n",
    "\n",
    "# we have to split lines now because pprint cannot take multiple arguments like print\n",
    "print(\"Most common Hamlet words:\")\n",
    "pprint(Counter.most_common(counts_hamlet, 100))\n",
    "print()\n",
    "print(\"Most common Faustus words:\")\n",
    "pprint(Counter.most_common(counts_faustus, 100))\n",
    "print()\n",
    "print(\"Most common John Carter words:\")\n",
    "pprint(Counter.most_common(counts_mars, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "What is the difference between the following two pieces of code?\n",
    "How do they differ in their output, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(hamlet[:50])\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count = Counter(hamlet)\n",
    "print(Counter.most_common(count, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*put your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A problem\n",
    "\n",
    "If you look at the lists of 100 most common words for each text, you'll notice that they are fairly similar.\n",
    "For instance, all of them have *a*, *the*, and *to* among the most frequent ones.\n",
    "That's not a peculiarity of these few texts, it's a general property of English texts.\n",
    "This is because of **Zipf's law**: ranking words by their frequency, the n-th word will have a relative frequency of 1/n.\n",
    "So the most common word is twice as frequent as the second most common one, three times more frequent than the third most common one, and so on.\n",
    "As a result, a handful of words make up over 50% of all words in a text.\n",
    "\n",
    "Zipf's law means that word frequencies in a text give rise to a peculiar shape that we might call the Zipf dinosaur.\n",
    "\n",
    "![The Zipf dinosaur](./media/zipfgraph_dinosaur.jpeg)\n",
    "\n",
    "A super-high neck, followed by a very long tail.\n",
    "For English texts, the distribution usually resembles the one below, and that's even though this graph only shows the most common words.\n",
    "\n",
    "![Zipf distribution for English](./media/zipfgraph_english.png)\n",
    "\n",
    "There is precious little variation between English texts with respect to which words are at the top.\n",
    "These common but uninformative words are called **stop words**.\n",
    "If we want to find any interesting differences between *Hamlet*, *Doctor Faustus*, and *Princess of Mars*, we have to filter out all these stop words.\n",
    "That's not something we can do by hand, but our existing box of tricks doesn't really seem to fit either.\n",
    "We could use a regular expression to delete all these words from the string before it even gets tokenized.\n",
    "But that's not the best solution:\n",
    "\n",
    "1. A minor mistake in the regular expression might accidentally delete many things we want to keep.\n",
    "   Odds are that this erroneous deletion would go unnoticed, possibly invalidating our stylistic analysis.\n",
    "1. There's hundreds of stop words, so the regular expression would be very long.\n",
    "   Ideally, our code should be compact and easy to read.\n",
    "   A super-long regular expression is the opposite of that, and it's no fun to type either.\n",
    "   And of course, the longer a regular expression, the higher the chance that you make a typo (which takes us back to point 1).\n",
    "1. While regular expressions are fast, they are not as fast as most of the operations Python can perform on lists and counters.\n",
    "   If there is an easy alternative to a regular expression, that alternative is worth exploring.\n",
    "\n",
    "Alright, so if regexes aren't the best solution, what's the alternative?\n",
    "Why, it's simple: 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing counts\n",
    "\n",
    "The values in a Python counter can be changed very easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "# define a test counter and show its values\n",
    "test = Counter([\"John\", \"said\", \"that\", \"Mary\", \"said\", \"that\", \"Bill\", \"stinks\"])\n",
    "pprint(test)\n",
    "\n",
    "# 'that' is a stop word; set its count to 0\n",
    "test[\"that\"] = 0\n",
    "pprint(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above uses the new notation `test['that']`.\n",
    "Remember that Python allows us reference specific elements with an index that corresponds to their position in the list, e.g. `some_list[2]`.\n",
    "Counters have no fixed orders, so we cannot use indices in this way.\n",
    "But instead of an index we can just use the element itself.\n",
    "So `test[\"that\"]` points to the value for `\"that\"` in the counter `test`.\n",
    "We also say that `\"that\"` is a **key** that points to a specific **value**.\n",
    "The line\n",
    "\n",
    "```python\n",
    "test[\"that\"] = 0\n",
    "```\n",
    "\n",
    "intstructs Python to set the value for the key `\"that\"` to `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Look at the code cell below.\n",
    "For each line, add a comment that briefly describes what it does (for instance, *set value of 'that' to 0*).\n",
    "If the line causes an error, fix the error and add two commments:\n",
    "\n",
    "1. What caused the error?\n",
    "1. What does the corrected line do?\n",
    "\n",
    "You might want to use `pprint` to look at how the counter changes after each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# define a test counter and show its values\n",
    "test = Counter([\"John\", \"said\", \"that\", \"Mary\", \"said\", \"that\", \"Bill\", \"stinks\"])\n",
    "\n",
    "test[\"that\"] = 0  # set value of 'that' to 0\n",
    "test[\"Mary\"] = test[\"that\"]\n",
    "test[John] = 10\n",
    "test[\"said\"] = test[\"John' - 'said\"]\n",
    "test[\"really\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can change the values of keys in counters, stop words become very easy to deal with.\n",
    "Recall that the problem with stop words is not so much that they occur in the counter, but that they make up the large majority of high frequency words.\n",
    "Our intended fix was to delete them from the counter.\n",
    "But instead, we can just set the count of each stop word to 0.\n",
    "Then every stop word is still technically contained by the counter, but since its frequency is 0 it will no longer show up among the most common words, which is what we really care about.\n",
    "\n",
    "Alright, let's do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "The figure above shows you the most common stop words of English (except for *whale*, you can ignore that one).\n",
    "Extend the code below so that the count for each one of the stop words listed in the figure is set to 0.\n",
    "Compare the output before and after stop word removal and ask yourself whether there has been significant progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# construct the counters\n",
    "counts_hamlet = Counter(hamlet)\n",
    "# output with stop words\n",
    "print(\"Most common Hamlet words before clean-up:\\n\", Counter.most_common(counts_hamlet, 25))\n",
    "\n",
    "# set stop word counts to 0\n",
    "# put your code here\n",
    "\n",
    "# output without stop words\n",
    "print(\"Most common Hamlet words after clean-up:\\n\", Counter.most_common(counts_hamlet, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is an improvement, but it's really tedious.\n",
    "You have to write the same code over and over again, changing only the key.\n",
    "And you aren't even done yet, there's still many more stop words to be removed.\n",
    "But don't despair, you don't have to add another 100 lines of code.\n",
    "No, repetitive tasks like that are exactly why programming languages have **`for` loops**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A new kind of loop: `for`\n",
    "\n",
    "You already know `while` loops, which keep executing the same code over and over again until a condition is no longer met.\n",
    "A `for` loop is similar in that it runs the same code over and over again.\n",
    "But instead of a condition, the `for` loop takes a collection of elements and runs the code once for each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some tedious repetition\n",
    "print(\"H\")\n",
    "print(\"e\")\n",
    "print(\"l\")\n",
    "print(\"l\")\n",
    "print(\"o\")\n",
    "print(\"!\")\n",
    "print(\"!\")\n",
    "print(\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a for-loop with a list as container is much shorter\n",
    "for character in [\"H\", \"e\", \"l\", \"l\", \"o\", \"!\", \"!\", \"!\"]:\n",
    "    print(character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# strings count as containers, too\n",
    "for character in \"Hello!!!\":\n",
    "    print(character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general format of a `for`-loop is very intuitive.\n",
    "\n",
    "```python\n",
    "for element in some_container:\n",
    "    # code to be run for each element\n",
    "```\n",
    "\n",
    "Just keep in mind that the container inside the `for`-loop gets run once for each element in the container.\n",
    "Many different kinds of objects can be containers, including lists and strings.\n",
    "Intuitively, if something is built up from smaller elements, it is a container.\n",
    "So `\"5\"` would be a container (a string built up from a single character), but `5` would not be (an integer isn't a collection of smaller things).\n",
    "\n",
    "Just like with `while`-loops, there are no restrictions on how complex the code inside a `for`-loop may be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for character in \"Hello!!!\":\n",
    "    character = str.lower(character)\n",
    "    if character in [\"a\", \"e\", \"i\", \"o\", \"u\"]:\n",
    "        print(\"Found a vowel:\", character)\n",
    "    else:\n",
    "        if character not in [\"!\", \".\", \"?\", \"-\", \";\", \" \"]:\n",
    "            print(\"Found a consonant:\", character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "The output of the code below might be unexpected to you.\n",
    "Explain what is going on here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# strings count as containers, too\n",
    "for character in [\"Hello!!!\"]:\n",
    "    print(character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*put your explanation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "The code below contains several mistakes.\n",
    "Fix all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_buy = [\"honey\"]\n",
    "\n",
    "for ingredient in \"flour\", \"sugar\", \"honey\"\n",
    "if ingredient not in to_buy:\n",
    "    list.append(to_buy, the_ingredient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Look at the code below.\n",
    "Provide a more succinct implementation that uses a `for`-loop instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The first natural number is 0.\")\n",
    "print(\"The number after that is 1.\")\n",
    "print(\"The number after that is 2.\")\n",
    "print(\"The number after that is 3.\")\n",
    "print(\"The number after that is 4.\")\n",
    "print(\"The number after that is 5.\")\n",
    "print(\"The number after that is 6.\")\n",
    "print(\"It goes on like that forever.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a `for`-loop, setting the counts of stop words to 0 becomes a matter of just a few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# construct the counters\n",
    "counts_hamlet = Counter(hamlet)\n",
    "counts_faustus = Counter(faustus)\n",
    "counts_mars = Counter(mars)\n",
    "\n",
    "stopwords = [\"the\", \"of\", \"and\", \"a\", \"to\", \"in\",\n",
    "             \"that\", \"his\", \"it\", \"he\", \"but\", \"as\",\n",
    "             \"is\", \"with\", \"was\", \"for\", \"all\", \"this\",\n",
    "             \"at\", \"while\", \"by\", \"not\", \"from\", \"him\",\n",
    "             \"so\", \"be\", \"one\", \"you\", \"there\", \"now\",\n",
    "             \"had\", \"have\", \"or\", \"were\", \"they\", \"which\",\n",
    "             \"like\"]\n",
    "\n",
    "for word in stopwords:\n",
    "    counts_hamlet[word] = 0\n",
    "    counts_faustus[word] = 0\n",
    "    counts_mars[word] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Since there's no limits on the complexity of the code inside a `for`-loop, it can also contain another `for`-loop.\n",
    "Copy-paste the code above into the cell below and replace the last three lines by a `for`-loop inside the stop word `for`-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put the modified code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "This continues the previous exercise.\n",
    "Keep expanding the list of stop words until the top 100 words for each text are sufficiently distinct for meaningful comparisons.\n",
    "It's up to you to decide when that is the case, but you want to see things like proper names, nouns, and adjectives, rather than just coordinations, pronouns, and forms of *have* or *be*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we can finally compare the three texts based on their unigram counts.\n",
    "You can use the `Counter.most_common` function to see which words are most common in each text.\n",
    "We can also compare the overall frequency distribution.\n",
    "The code below will plot the counters, giving you a graphical representation of the frequency distribution, similar to the Zipf figures above.\n",
    "\n",
    "(Don't worry about what any of the code below does.\n",
    "Just run the cell and look at the pretty output.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# import relevant matplotlib code\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# figsize(20, 10)\n",
    "plt.figure(figsize=(20,10))\n",
    "# the lines above are needed for Jupyter to display the plots in your browser\n",
    "# do not remove them\n",
    "\n",
    "# a little bit of preprocessing so that the data is ordered by frequency\n",
    "def plot_preprocess(the_counter, n):\n",
    "    \"\"\"format data for plotting n most common items\"\"\"\n",
    "    sorted_list = sorted(the_counter.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    words, counts = zip(*sorted_list)\n",
    "    return words, counts\n",
    "\n",
    "\n",
    "for text in [counts_hamlet, counts_faustus, counts_mars]:\n",
    "    # you can change the max words value to look at more or fewer words in one plot\n",
    "    max_words = 30\n",
    "    words = plot_preprocess(text, max_words)[0]\n",
    "    counts = plot_preprocess(text, max_words)[1]\n",
    "    plt.bar(range(len(counts)), counts, align=\"center\")\n",
    "    plt.xticks(range(len(words)), words)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there you have it.\n",
    "Your first, fairly simple quantitative analysis of writing style.\n",
    "You can compare the three texts among several dimensions:\n",
    "\n",
    "1. What are the most common words in each text?\n",
    "1. Are the frequency distributions very different?\n",
    "   Perhaps one of them keeps repeating the same words over and over, whereas another author varies their vocabulary more and thus has a smoother curve that's not as much tilted towards the left?\n",
    "   \n",
    "Play around with this a bit.\n",
    "You can change the `max_words` variable in the code above to \"zoom in\" and \"zoom out\".\n",
    "But keep in mind that it might take a while to compute the plots for values past 100.\n",
    "\n",
    "We're of course far away from a truly insightful analysis of these texts.\n",
    "But this is in fact how a lot of language technology works.\n",
    "For example, there are algorithms that determine what ads to place on a given website depending on its content.\n",
    "Except that the analysis of the content doesn't go much beyond calculating what words that aren't stop words are most frequent in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bullet point summary\n",
    "    \n",
    "- **Counters**\n",
    "    - Counters count the number of tokens for each type in a list.\n",
    "    - Load them with `from collections import Counter`.\n",
    "    - Use `some_counter = Counter(some_list)` to convert `some_list` to a counter `some_counter`.\n",
    "    - Use `Counter.most_common(your_counter, n)` to get the `n` most common words in the counter.\n",
    "    - Use `some_counter[some_key]` to get the value of `some_key`.\n",
    "      Don't forget the quotation marks for strings.\n",
    "    - Values can also be modified, e.g. `some_counter[some_key] = some_counter[other_key] + 5`.\n",
    "    \n",
    "- **Loading libraries**  \n",
    "  When loading only a part of a library, you can use `from libraryX import partY` instead of `import libraryX`.\n",
    "  Then you can simple write `partY` in your code instead of `libraryX.partY`.\n",
    "      \n",
    "    ```python\n",
    "    from re import sub\n",
    "    # we now use sub instead of re.sub\n",
    "    sub(r\"\\d+\", \"\", some_string)\n",
    "    ```\n",
    "    \n",
    "  By default, you should use `import X`.\n",
    "  Only use `from X import Y` if\n",
    "    1. `X` is a pretty long library name, and\n",
    "    1. you need to use `Y` a lot, and\n",
    "    1. you really need only `Y` and none of the other functions provided by `X`.\n",
    "   \n",
    "- **`for`-loops**\n",
    "  Use `for`-loops to apply a piece of code to each element in a collection.\n",
    "  \n",
    "    ```python\n",
    "    for element in collection:\n",
    "        # do something; you may use element as a variable\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
