{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature analysis with n-grams: The drudgery\n",
    "\n",
    "Now that you have seen a few simple applications that use tokenization, it's time to look at something more realistic.\n",
    "As you probably know from your English homeworks, comparing works of fiction can be a very hard and time-consuming task.\n",
    "It would be much nicer if we could just have the computer do all the work.\n",
    "But how could that work?\n",
    "\n",
    "One simple idea is that an author's style is represented by which words (s)he uses, and in particular which words (s)he uses most.\n",
    "Words are also known as *unigrams*.\n",
    "This is in contrast to *bigrams*, which consist of two words, *trigrams* (three words), and so on.\n",
    "For instance, the sentence\n",
    "\n",
    "    John likes Mary and Peter\n",
    "    \n",
    "contains the unigrams\n",
    "\n",
    "    John, likes, Mary, and, Peter\n",
    "    \n",
    "the bigrams\n",
    "\n",
    "    John likes, likes Mary, Mary and, and Peter\n",
    "    \n",
    "and the trigrams\n",
    "\n",
    "    John likes Mary, likes Mary and, Mary and Peter\n",
    "    \n",
    "We could also have 4-grams, 5-grams, or 127-grams.\n",
    "Quite generally, a model that is based on words or sequences of words is called an *n-gram model*.\n",
    "So if we want to analyze an author's style in terms of their word usage, we are proposing a unigram model of stylistic analysis.\n",
    "\n",
    "But does a unigram model actually work?\n",
    "Well, let's put the idea to the test: we will compare three works of fiction comparing this technique:\n",
    "\n",
    "- William Shakespeare's *Hamlet*\n",
    "- Christopher Marlowe's *The Tragical History of Dr. Faustus*\n",
    "- Edgar Rice Burrough's *A Princess of Mars*\n",
    "\n",
    "If we find something interesting, then unigram models might be worthwhile after all.\n",
    "\n",
    "A brief remark on those works: The first two are world-famous Victorian plays, whereas the third is an early 20th century pulp novel that you might know as the basis for Disney's 2012 box office debacle *John Carter*. Although the movie is better than its reputation, it still doesn't do justice to the book, so give it a read if you are in the mood for a fun science fantasy story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the files\n",
    "\n",
    "First we need to have the books in some digital format that we can feed into Python.\n",
    "Ideally, we want this to be a plaintext format, i.e. the pure text without any layout information.\n",
    "We do not want a pdf or doc file, as those are much harder to work with.\n",
    "We can use Python to download all the files from [Project Gutenberg](https://www.gutenberg.org/), an online platform that hosts literary works that are no longer under copyright.\n",
    "\n",
    "To do so, we first import the library `urllib.request` and then use the following command:\n",
    "\n",
    "```python\n",
    "urllib.request.urlretrieve(\"url_to_download\", \"filename_of_your_choice\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://www.gutenberg.org/files/1524/1524-h/1524-h.htm\", \"hamlet.txt\")\n",
    "urllib.request.urlretrieve(\"https://www.gutenberg.org/cache/epub/811/pg811.txt\", \"faustus.txt\")\n",
    "urllib.request.urlretrieve(\"https://www.gutenberg.org/cache/epub/62/pg62.txt\", \"mars.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Browse Project Gutenberg and find a book you really like.\n",
    "Keep in mind that Project Gutenberg only has texts that are in the public domain, which means that they are no longer copy-righted.\n",
    "So you won't see *Harry Potter*, *Hunger Games*, or even Stephen King's *It* there, but almost everything from the 19th century and earlier can be found there.\n",
    "\n",
    "Once you have picked a book, look at the different file formats.\n",
    "You might see html (for display in web browsers), epub (an ebook format), and txt (plaintext, usually the easiest format for computational analysis).\n",
    "Download one of them using the `urllib.request.urlretrieve` command and save it as `mybookpick.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code above should have put three files in the folder you are running this notebook from:\n",
    "\n",
    "1.  `faustus.txt`\n",
    "1.  `hamlet.txt`\n",
    "1.  `mars.txt`\n",
    "\n",
    "You can open them in CoCalc to look at their contents.\n",
    "If you're not using CoCalc, open them with a text editor, for example Notepad if your computer is running Windows.\n",
    "Scroll up and down a bit to get a better idea of what the files look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Write down a list of the things that stand out to you in these files.\n",
    "In particular:\n",
    "\n",
    "1. Do the files look the same, or are there major differences?\n",
    "1. Do the files just contain the text of the plays, or also additional information (check the top and bottom of each file carefully)?\n",
    "1. If we want just the words used by the protagonists of the plays, what changes need to made to the files?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*put your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the files\n",
    "\n",
    "### Analysis\n",
    "\n",
    "You should have noticed quite a few problems with the files, only some of which we can fix by hand.\n",
    "\n",
    "1. While `faustus.txt` and `mars.txt` are fairly easy to read, `hamlet.txt` is cluttered with all kinds of weird code like `<p>` and `<br/>`. That's because we downloaded a textfile for `faustus.txt` and `mars.txt`, but an html-file for `hamlet.txt`. The expressions between `<` and `>` are html-markup, which is needed to display a file in a webbrowser.\n",
    "\n",
    "1. All files start with information about Project Gutenberg, which we do not want.\n",
    "\n",
    "1. All files have information at the end that is not part of the play. In `hamlet.txt` and `mars.txt`, it's just a disclaimer that the play is over, whereas `faustus.txt` is also full of footnotes.\n",
    "\n",
    "1. In `faustus.txt`, the text is often interrupted by strings like `[17]`. Those are references to footnotes.\n",
    "\n",
    "1. For the two plays, slightly different formats are used to indicate who is speaking.\n",
    "    - In `hamlet.txt`, names are fully capitalized and occur between the markup `<p>` and `<br/>`.\n",
    "      Sometimes there is a dot after the name, sometimes there isn't.\n",
    "    - In `faustus.txt`, names are fully capitalized and followed by a dot.\n",
    "      The actual text usually starts on the same line.\n",
    "    \n",
    "1. In `faustus.txt`, stage instructions are indicated by indentation.\n",
    "   In `hamlet.txt`, they occur between `<p class=\"scenedesc\">` and `</p>`.\n",
    "\n",
    "1. In `faustus.txt`, all dialog is indented, but less so than the stage instructions.\n",
    "    \n",
    "1. All three files contain many empty lines.\n",
    "\n",
    "1. Both plays capitalize words at the beginning of a new line.\n",
    "\n",
    "1. In `mars.txt`, Chapters are written in upper caps.\n",
    "\n",
    "These are all problematic for us:\n",
    "\n",
    "- We just want to be able to see which words are used in each play, and how often each word is used.\n",
    "- We do not want HTML markup, information about Project Gutenberg, footnotes, or empty lines.\n",
    "- We also do not want to keep track of names if they just indicate who is speaking. That's not part of the play as such.\n",
    "- We should also exclude stage instructions because those do not belong to the literary part of the play either.\n",
    "\n",
    "Fixing all these things by hand would be tons of work.\n",
    "Fortunately, we only need to delete a few things by hand, while Python can do the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up\n",
    "\n",
    "Let's first do the manual fixes.\n",
    "Carry out the fixes below, then save the modified files under new names so that they don't get overwritten in case you redownload the files: `hamlet_manual.txt`, `faustus_manual.txt`, and `mars_manual.txt`.\n",
    "\n",
    "1. Open `hamlet.txt` and delete the first 189 lines. That's everything before the line `<h4><b>SCENE. Elsinore.</b></h4>`.\n",
    "\n",
    "1. Now go to the end of `hamlet.txt` and delete everything after line 7942. That's everything after (and including) the line with the single tag `<pre>`. It is the only such tag in the file, so it is easy to find with your editor's search function.\n",
    "\n",
    "1. Open `faustus.txt` and delete the first 140 lines. That's everything up to and including the empty line right after `FROM THE QUARTO OF 1616.`\n",
    "\n",
    "1. In the same file, delete everything after the line `Terminat hora diem; terminat auctor opus.`\n",
    "   Use the editor's search function to find it quickly.\n",
    "   \n",
    "1. Open `mars.txt` and delete the first 235 lines. That's everything before the line that says `CHAPTER I`.\n",
    "\n",
    "1. In the same file, delete everything after the line `that I shall soon know.`\n",
    "\n",
    "We have removed quite a bit of unwanted stuff, but there's still many problems with the formatting.\n",
    "The Python code below fixes all of those for us using the power of regular expressions.\n",
    "\n",
    "The code uses several commands we haven't encountered before, such as `with`, `raise`, and `for`, as well as advanced regular expression techniques.\n",
    "Ignore them, they're not the point of this unit (`for` will be explained in the next unit, and there's separate expansion units for `with` and `raise`).\n",
    "The important thing is that we now have a function `text_cleaner` that will clean up the text for us.\n",
    "Remember, that's the great thing about functions - you can treat them as blackboxes and use them efficiently even if you don't fully understand how they work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code to clean up hamlet.txt, faustus.txt, and mars.txt\n",
    "# ======================================================\n",
    "\n",
    "# import regular expression module\n",
    "import re\n",
    "\n",
    "def text_cleaner(filename):\n",
    "    \"\"\"\n",
    "    Open text and run required cleaning procedures.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    filename: str\n",
    "        name of file without extension (for instance .txt)\n",
    "    \"\"\"\n",
    "    # Step 1: load file and store it as variable \"text\"\n",
    "    with open(filename + \"_manual.txt\", mode=\"r\", encoding='utf-8-sig') as text:\n",
    "        # Step 2: create a new file to save cleaned up version\n",
    "        with open(filename + \"_clean.txt\", mode=\"w\", encoding='utf-8') as cleaned:\n",
    "            # Step 2.5: hamlet needs some special tricks for multiline scene descriptions\n",
    "            text = text.read()\n",
    "            if filename == \"hamlet\":\n",
    "                text = re.sub(r'<p.*?class=\"scenedesc\".*?>[\\s\\S]*?</p>', r'', text)\n",
    "            # Step 3: clean each line and write to clean-up file\n",
    "            for line in str.split(text, '\\n'):\n",
    "                # cleaning\n",
    "                line = line_cleaner(filename, line)\n",
    "                # write line if it isn't empty\n",
    "                if line != '':\n",
    "                    cleaned.write(line)\n",
    "                    cleaned.write('\\n')\n",
    "\n",
    "                    \n",
    "def line_cleaner(filename, line):\n",
    "    \"\"\"clean line for hamlet, faustus, and mars\"\"\"\n",
    "    # hamlet-specific cleaning\n",
    "    if filename == \"hamlet\":\n",
    "        # 1. remove all headers\n",
    "        line = re.sub(r'<h[0-9].*', r'', line)\n",
    "        # 2. remove speaker information\n",
    "        #    (identified by html tags)\n",
    "        line = re.sub(r'<p.*?>[A-Z\\. ]*?<br/>', r'', line)\n",
    "        # 3. remove html tags\n",
    "        line = re.sub(r'<.*?>', r'', line)\n",
    "        # 4. remove anything after [ or before ]\n",
    "        line = re.sub(r'\\[[^\\]]*', r'', line)\n",
    "        line = re.sub(r'[^\\[]*\\]', r'', line)\n",
    "        # 5. replace special html codes by characters\n",
    "        line = re.sub(r'&[rl]squo;', r\"'\", line)\n",
    "        line = re.sub(r'&mdash;', r\" --- \", line)\n",
    "        line = re.sub(r\"&amp;c[\\.,]\", r\"&\", line)\n",
    "    # faustus-specific cleaning\n",
    "    elif filename == \"faustus\":\n",
    "        # 1. remove stage information\n",
    "        #    (anything after 10 spaces)\n",
    "        line = re.sub(r'(\\s){10}.*', r'', line)\n",
    "        # 2. remove speaker information\n",
    "        #    (any word in upper caps followed by space or dot)\n",
    "        line = re.sub(r'[A-Z]{2,}[\\s\\.]', r'', line)\n",
    "        # 3. remove anything between square brackets\n",
    "        line = re.sub(r'\\[[^\\]]*\\]', r'', line)\n",
    "        # 4. remove sentence initial spaces\n",
    "        line = re.sub(r'^\\s+', r'', line)\n",
    "    # mars-specific cleaning\n",
    "    elif filename == \"mars\":\n",
    "        # 1. delete CHAPTER I\n",
    "        # (must be done like this because Roman 1 looks like English I)\n",
    "        line = re.sub('CHAPTER I', '', line)\n",
    "        # 2. remove any word in upper caps\n",
    "        line = re.sub(r'[A-Z]{2,}[\\s\\.]?', r'', line)\n",
    "        # 3. remove anything after [ or before ]\n",
    "        line = re.sub(r'\\[[^\\]]*', r'', line)\n",
    "        line = re.sub(r'[^\\[]*\\]', r'', line)\n",
    "    else:\n",
    "        # give an error message\n",
    "        raise Exception(\"No cleaning profile exists for this file\")\n",
    "    # remove multiple spaces that might be left after clean up\n",
    "    line = re.sub(r'\\s+', ' ', line)\n",
    "    # return cleaned up line with everything in lower case\n",
    "    return str.lower(line)\n",
    "        \n",
    "# do the actual cleaning\n",
    "for filename in [\"hamlet\", \"faustus\", \"mars\"]:\n",
    "    text_cleaner(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the code, open the newly creates files `faustus_clean.txt`, `hamlet_clean.txt`, and `mars_clean.txt` in your text editor.\n",
    "Contrast them to `faustus_manual.txt`, `hamlet_manual.txt`, and `mars_manual.txt` that were fed into the cleaning function.\n",
    "All the unwanted annotations, markup and stage instructions are gone, and we have a much cleaner file now.\n",
    "Also note that now all words are lowercase, including proper names.\n",
    "That is a feature, not a bug: *but* and *But* are the same word, so we do not want to count them separately.\n",
    "That the texts now talk about *hamlet*, *faustus*, and *carter* is not much of an issue since proper names are rarely identical to existing words.\n",
    "\n",
    "Cleaning up files isn't too much fun, but it is really necessary.\n",
    "Always remember the old saying: **garbage in, garbage out!**\n",
    "We have to make sure our data is a clean as possible in order to carry out a good analysis.\n",
    "But now we can finally get started on the fun part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Remember that we are interested in determining which words each author uses, and how often they do so.\n",
    "As far as Python is concerned, our text files are just a very long string of random characters.\n",
    "Python has no understanding of what a word is, so it cannot count words without our help.\n",
    "What we need to do is to tell Python how it can convert a string into a list of words.\n",
    "And as you know by now, that's exactly what tokenizers are for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(the_string):\n",
    "    \"\"\"Convert string to list of words\"\"\"\n",
    "    return re.findall(r\"\\w+\", the_string)\n",
    "\n",
    "\n",
    "def tokenize_file(the_file):\n",
    "    \"\"\"Read file as string and tokenize it\"\"\"\n",
    "    with open(the_file, mode=\"r\") as text:\n",
    "        return tokenize(text.read())\n",
    "\n",
    "\n",
    "# define a variable for each token list\n",
    "hamlet = tokenize_file(\"hamlet_clean.txt\")\n",
    "faustus = tokenize_file(\"faustus_clean.txt\")\n",
    "mars = tokenize_file(\"mars_clean.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, let's see what these lists looks like compared to what we would get without the prior clean-up step.\n",
    "After all, if we put so much effort in cleaning up the files, we want to know that it has paid off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "You could look at the cleaned-up lists with the `print` command:\n",
    "\n",
    "```python\n",
    "print(hamlet)\n",
    "print(faustus)\n",
    "print(mars)\n",
    "```\n",
    "\n",
    "**Don't do that!!!**\n",
    "\n",
    "The output would be huge because these are long texts.\n",
    "Use the `len` function to check how long each text is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know, we can use indices to look at individual elements of a list.\n",
    "So we can, say, compare the first word in the original version to the cleaned-up version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamlet comparison\n",
      "-----------------\n",
      "First word in Hamlet before cleaning: h4\n",
      "First word in Hamlet after cleaning: who\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(the_string):\n",
    "    \"\"\"Convert string to list of words\"\"\"\n",
    "    return re.findall(r\"\\w+\", the_string)\n",
    "\n",
    "\n",
    "def tokenize_file(the_file):\n",
    "    \"\"\"Read file as string and tokenize it\"\"\"\n",
    "    with open(the_file, mode=\"r\") as text:\n",
    "        return tokenize(text.read())\n",
    "\n",
    "\n",
    "# define a variable for each token list\n",
    "hamlet = tokenize_file(\"hamlet_clean.txt\")\n",
    "faustus = tokenize_file(\"faustus_clean.txt\")\n",
    "mars = tokenize_file(\"mars_clean.txt\")\n",
    "\n",
    "# and the counterparts without cleaning up\n",
    "hamlet_manual = tokenize_file(\"hamlet_manual.txt\")\n",
    "faustus_manual = tokenize_file(\"faustus_manual.txt\")\n",
    "mars_manual = tokenize_file(\"mars_manual.txt\")\n",
    "\n",
    "print(\"Hamlet comparison\")\n",
    "print(\"-----------------\")\n",
    "print(\"First word in Hamlet before cleaning:\", hamlet_manual[0])\n",
    "print(\"First word in Hamlet after cleaning:\", hamlet[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caution:**\n",
    "The rest of this notebook assumes that the variables `hamlet`, `faustus`, and `mars` exist, and similarly for `hamlet_manual`, `faustus_manual`, and `mars_manual`.\n",
    "That's the case if you have run the cell above.\n",
    "But if you restart the kernel at a later point, you have to rerun the cell above so that the variables are defined again.\n",
    "So if you run one of the cells below and get an error that `hamlet`, `faustus`, or `mars` are undefined, come back up here and run the code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But obviously it would be very tedious to compare, say, the first 100 words this way.\n",
    "Fortunately, Python's got us covered.\n",
    "The index notation can also be used to get **slices**.\n",
    "A slice is a continuous part of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'really']\n",
      "['really', 'likes', 'Sue']\n"
     ]
    }
   ],
   "source": [
    "# a short list\n",
    "example_list = [\"John\", \"really\", \"likes\", \"Sue\"]\n",
    "# show the first two elements\n",
    "print(example_list[0:2])\n",
    "# show the slice from index 1 to 4\n",
    "print(example_list[1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slices are very easy to use:\n",
    "\n",
    "```python\n",
    "some_list[start_index:end_index]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Experimentation time!\n",
    "Play around with slices to figure out how they work.\n",
    "Pay particular attention to the following issues:\n",
    "\n",
    "1. What happens if the start index is greater than the end index?\n",
    "1. What happens if the end index does not exist (e.g. 17 for the example list above)?\n",
    "1. What happens if one of the indices is omitted?\n",
    "   For instance, `example_list[:3]`, or `example_list[2:]`, or `example_list[-1:]`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# experiment here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*put your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With slices, it is now very easy to compare specific passages of the texts.\n",
    "For example, we can look at the first 50 words in each text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "['who', 's', 'there', 'nay', 'answer', 'me', 'stand', 'and', 'unfold', 'yourself', 'long', 'live', 'the', 'king', 'barnardo', 'he', 'you', 'come', 'most', 'carefully', 'upon', 'your', 'hour', 'tis', 'now', 'struck', 'twelve', 'get', 'thee', 'to', 'bed', 'francisco', 'for', 'this', 'relief', 'much', 'thanks', 'tis', 'bitter', 'cold', 'and', 'i', 'am', 'sick', 'at', 'heart', 'have', 'you', 'had', 'quiet']\n",
      "--------\n",
      "--------\n",
      "['h4', 'b', 'SCENE', 'Elsinore', 'b', 'h4', 'p', 'br', 'p', 'p', 'class', 'scene', 'a', 'name', 'sceneI_1', 'id', 'sceneI_1', 'a', 'p', 'h3', 'b', 'ACT', 'I', 'b', 'h3', 'h4', 'b', 'SCENE', 'I', 'Elsinore', 'A', 'platform', 'before', 'the', 'Castle', 'b', 'h4', 'p', 'class', 'scenedesc', 'Enter', 'span', 'class', 'charname', 'Francisco', 'span', 'and', 'span', 'class', 'charname']\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "def print_50(the_list):\n",
    "    print(\"--------\")\n",
    "    print(the_list[:50])\n",
    "    print(\"--------\")\n",
    "    \n",
    "print_50(hamlet)\n",
    "print_50(hamlet_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Write a small custom function `print_first_last` that prints the first *n* and last *n* words of each one of the three texts.\n",
    "For example, `print_first_last(5)` should print the first 5 words of `hamlet`, then the last 5 words of `hamlet`, and then the same for `faustus` and `mars`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparisons of the lists with and without cleaning show how important it is to remove all unneccessary crud from the files you work with.\n",
    "The list over the cleaned file looks like the actual beginning of *Hamlet*, the other one not so much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting words\n",
    "\n",
    "A tokenized list is nice, but not enough.\n",
    "Slices make it easier for us to compare two versions of the same file, but that's not quite what we want either.\n",
    "In order to carry out a quantitative analysis of each author's writing style, we also need to know how often each word is used.\n",
    "\n",
    "Python makes this very easy for us: the `collections` library provides a function `Counter` that does the counting for us.\n",
    "The `Counter` function takes as its only argument a list (like the ones produced by `re.findall` for tokenization).\n",
    "It then converts the list into a *Counter*.\n",
    "Here is what this looks like with a short example string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of tokens: ['ftl', 'is', 'short', 'for', 'faster', 'than', 'light', 'we', 'probably', 'won', 't', 'ever', 'have', 'space', 'ships', 'capable', 'of', 'ftl', 'travel']\n",
      "\n",
      "Number of tokens for each word type: Counter({'ftl': 2, 'for': 1, 'of': 1, 'won': 1, 'faster': 1, 'space': 1, 't': 1, 'travel': 1, 'probably': 1, 'we': 1, 'short': 1, 'ships': 1, 'than': 1, 'is': 1, 'have': 1, 'capable': 1, 'ever': 1, 'light': 1})\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter  # this allows us to use Counter instead of collections.Counter\n",
    "\n",
    "test_string = \"FTL is short for faster-than-light; we probably won't ever have space ships capable of FTL-travel.\"\n",
    "\n",
    "# tokenize the string\n",
    "tokens = re.findall(r\"\\w+\", str.lower(test_string))\n",
    "print(\"The list of tokens:\", tokens)\n",
    "\n",
    "# add an empty line\n",
    "print()\n",
    "\n",
    "# and now do the counting\n",
    "counts = Counter(tokens)\n",
    "print(\"Number of tokens for each word type:\", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick peak at what the counts looks like for each text.\n",
    "We don't want to do this with something like `print(counts_hamlet)`, because the output would be so large that your browser might actually choke on it (it has happened to me sometimes).\n",
    "Instead, we will look at the 100 most common words.\n",
    "We can do this with the function `Counter.most_common`, which takes two arguments: a Counter, and a positive number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common Hamlet words: [('the', 1054), ('and', 926), ('to', 728), ('of', 660), ('i', 623), ('you', 558), ('my', 516), ('a', 516), ('in', 433), ('it', 420), ('that', 405), ('is', 357), ('not', 314), ('this', 300), ('his', 295), ('d', 285), ('but', 263), ('with', 261), ('for', 252), ('your', 242), ('s', 235), ('me', 235), ('he', 231), ('as', 227), ('be', 222), ('what', 218), ('lord', 217), ('so', 198), ('him', 194), ('have', 183), ('will', 170), ('do', 161), ('o', 155), ('we', 152), ('no', 142), ('on', 136), ('are', 130), ('our', 119), ('if', 117), ('by', 117), ('all', 115), ('shall', 114), ('or', 113), ('good', 110), ('thou', 107), ('let', 105), ('come', 104), ('they', 98), ('now', 96), ('more', 96), ('there', 95), ('t', 95), ('from', 95), ('her', 91), ('how', 88), ('hamlet', 87), ('thy', 86), ('was', 86), ('at', 85), ('like', 84), ('most', 82), ('would', 81), ('ll', 78), ('know', 78), ('king', 77), ('well', 77), ('sir', 75), ('tis', 74), ('them', 74), ('us', 71), ('may', 71), ('father', 70), ('go', 70), ('love', 68), ('did', 66), ('very', 66), ('hath', 64), ('which', 63), ('speak', 63), ('then', 63), ('why', 62), ('here', 62), ('must', 60), ('give', 59), ('thee', 58), ('such', 58), ('where', 57), ('man', 57), ('their', 57), ('upon', 57), ('should', 56), ('th', 56), ('make', 56), ('say', 55), ('when', 55), ('am', 55), ('out', 53), ('an', 52), ('some', 52), ('she', 51)]\n",
      "\n",
      "Most common Faustus words: [('and', 509), ('the', 502), ('i', 400), ('of', 338), ('to', 333), ('that', 227), ('a', 212), ('in', 189), ('me', 187), ('faustus', 181), ('you', 176), ('my', 169), ('for', 161), ('thou', 154), ('d', 152), ('this', 146), ('not', 139), ('be', 137), ('is', 136), ('his', 134), ('with', 134), ('s', 117), ('what', 116), ('but', 114), ('it', 104), ('will', 98), ('we', 98), ('have', 97), ('all', 96), ('he', 94), ('as', 93), ('him', 92), ('now', 90), ('o', 85), ('thee', 79), ('shall', 78), ('ll', 77), ('then', 77), ('come', 76), ('your', 74), ('so', 72), ('are', 70), ('do', 67), ('thy', 66), ('see', 60), ('hell', 58), ('no', 54), ('on', 54), ('or', 51), ('may', 50), ('our', 48), ('soul', 48), ('if', 47), ('from', 46), ('an', 45), ('at', 44), ('mephistophilis', 44), ('by', 44), ('these', 42), ('let', 42), ('us', 42), ('tell', 41), ('am', 41), ('ay', 40), ('art', 39), ('how', 38), ('was', 38), ('they', 38), ('here', 37), ('sir', 36), ('them', 35), ('into', 35), ('make', 35), ('there', 34), ('go', 33), ('heaven', 33), ('lucifer', 32), ('where', 32), ('world', 32), ('lord', 31), ('hath', 30), ('doctor', 30), ('god', 30), ('why', 30), ('horse', 30), ('would', 29), ('their', 29), ('had', 29), ('must', 29), ('some', 29), ('can', 28), ('take', 28), ('such', 28), ('devil', 28), ('one', 27), ('again', 27), ('more', 27), ('good', 27), ('upon', 27), ('emperor', 26)]\n",
      "\n",
      "Most common John Carter words: [('the', 4530), ('of', 2527), ('and', 2287), ('i', 1877), ('to', 1668), ('a', 1259), ('my', 951), ('in', 935), ('was', 822), ('that', 759), ('as', 725), ('me', 669), ('had', 659), ('with', 563), ('for', 526), ('it', 491), ('but', 436), ('which', 429), ('upon', 428), ('from', 419), ('his', 417), ('he', 381), ('her', 375), ('not', 374), ('you', 365), ('were', 337), ('at', 329), ('we', 317), ('they', 306), ('she', 293), ('by', 291), ('have', 274), ('their', 264), ('is', 261), ('on', 254), ('one', 254), ('this', 224), ('be', 216), ('would', 213), ('could', 208), ('so', 202), ('an', 197), ('all', 195), ('them', 193), ('him', 180), ('or', 176), ('thoris', 172), ('dejah', 172), ('than', 170), ('are', 170), ('no', 169), ('great', 161), ('been', 160), ('our', 158), ('before', 146), ('there', 144), ('then', 143), ('into', 140), ('other', 133), ('when', 131), ('who', 128), ('us', 128), ('your', 127), ('only', 121), ('toward', 121), ('sola', 121), ('warriors', 117), ('little', 117), ('did', 114), ('martian', 110), ('some', 107), ('helium', 107), ('out', 107), ('green', 105), ('two', 102), ('men', 100), ('these', 99), ('now', 98), ('about', 97), ('first', 97), ('s', 95), ('tarkas', 94), ('tars', 94), ('city', 92), ('after', 91), ('through', 91), ('what', 90), ('time', 89), ('feet', 88), ('more', 88), ('do', 87), ('where', 86), ('up', 85), ('man', 84), ('over', 81), ('until', 81), ('without', 80), ('down', 78), ('barsoom', 77), ('long', 76)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# construct the counters\n",
    "counts_hamlet = Counter(hamlet)\n",
    "counts_faustus = Counter(faustus)\n",
    "counts_mars = Counter(mars)\n",
    "\n",
    "print(\"Most common Hamlet words:\", Counter.most_common(counts_hamlet, 100))\n",
    "print()\n",
    "print(\"Most common Faustus words:\", Counter.most_common(counts_faustus, 100))\n",
    "print()\n",
    "print(\"Most common John Carter words:\", Counter.most_common(counts_mars, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that doesn't look too bad, but the output is somewhat convoluted.\n",
    "We can use the function `pprint` from the `pprint` library to have each word on its own line.\n",
    "The name *pprint* is short for *pretty-print*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common Hamlet words:\n",
      "[('the', 1054),\n",
      " ('and', 926),\n",
      " ('to', 728),\n",
      " ('of', 660),\n",
      " ('i', 623),\n",
      " ('you', 558),\n",
      " ('my', 516),\n",
      " ('a', 516),\n",
      " ('in', 433),\n",
      " ('it', 420),\n",
      " ('that', 405),\n",
      " ('is', 357),\n",
      " ('not', 314),\n",
      " ('this', 300),\n",
      " ('his', 295),\n",
      " ('d', 285),\n",
      " ('but', 263),\n",
      " ('with', 261),\n",
      " ('for', 252),\n",
      " ('your', 242),\n",
      " ('s', 235),\n",
      " ('me', 235),\n",
      " ('he', 231),\n",
      " ('as', 227),\n",
      " ('be', 222),\n",
      " ('what', 218),\n",
      " ('lord', 217),\n",
      " ('so', 198),\n",
      " ('him', 194),\n",
      " ('have', 183),\n",
      " ('will', 170),\n",
      " ('do', 161),\n",
      " ('o', 155),\n",
      " ('we', 152),\n",
      " ('no', 142),\n",
      " ('on', 136),\n",
      " ('are', 130),\n",
      " ('our', 119),\n",
      " ('if', 117),\n",
      " ('by', 117),\n",
      " ('all', 115),\n",
      " ('shall', 114),\n",
      " ('or', 113),\n",
      " ('good', 110),\n",
      " ('thou', 107),\n",
      " ('let', 105),\n",
      " ('come', 104),\n",
      " ('they', 98),\n",
      " ('now', 96),\n",
      " ('more', 96),\n",
      " ('there', 95),\n",
      " ('t', 95),\n",
      " ('from', 95),\n",
      " ('her', 91),\n",
      " ('how', 88),\n",
      " ('hamlet', 87),\n",
      " ('thy', 86),\n",
      " ('was', 86),\n",
      " ('at', 85),\n",
      " ('like', 84),\n",
      " ('most', 82),\n",
      " ('would', 81),\n",
      " ('ll', 78),\n",
      " ('know', 78),\n",
      " ('king', 77),\n",
      " ('well', 77),\n",
      " ('sir', 75),\n",
      " ('tis', 74),\n",
      " ('them', 74),\n",
      " ('us', 71),\n",
      " ('may', 71),\n",
      " ('father', 70),\n",
      " ('go', 70),\n",
      " ('love', 68),\n",
      " ('did', 66),\n",
      " ('very', 66),\n",
      " ('hath', 64),\n",
      " ('which', 63),\n",
      " ('speak', 63),\n",
      " ('then', 63),\n",
      " ('why', 62),\n",
      " ('here', 62),\n",
      " ('must', 60),\n",
      " ('give', 59),\n",
      " ('thee', 58),\n",
      " ('such', 58),\n",
      " ('where', 57),\n",
      " ('man', 57),\n",
      " ('their', 57),\n",
      " ('upon', 57),\n",
      " ('should', 56),\n",
      " ('th', 56),\n",
      " ('make', 56),\n",
      " ('say', 55),\n",
      " ('when', 55),\n",
      " ('am', 55),\n",
      " ('out', 53),\n",
      " ('an', 52),\n",
      " ('some', 52),\n",
      " ('she', 51)]\n",
      "\n",
      "Most common Faustus words:\n",
      "[('and', 509),\n",
      " ('the', 502),\n",
      " ('i', 400),\n",
      " ('of', 338),\n",
      " ('to', 333),\n",
      " ('that', 227),\n",
      " ('a', 212),\n",
      " ('in', 189),\n",
      " ('me', 187),\n",
      " ('faustus', 181),\n",
      " ('you', 176),\n",
      " ('my', 169),\n",
      " ('for', 161),\n",
      " ('thou', 154),\n",
      " ('d', 152),\n",
      " ('this', 146),\n",
      " ('not', 139),\n",
      " ('be', 137),\n",
      " ('is', 136),\n",
      " ('his', 134),\n",
      " ('with', 134),\n",
      " ('s', 117),\n",
      " ('what', 116),\n",
      " ('but', 114),\n",
      " ('it', 104),\n",
      " ('will', 98),\n",
      " ('we', 98),\n",
      " ('have', 97),\n",
      " ('all', 96),\n",
      " ('he', 94),\n",
      " ('as', 93),\n",
      " ('him', 92),\n",
      " ('now', 90),\n",
      " ('o', 85),\n",
      " ('thee', 79),\n",
      " ('shall', 78),\n",
      " ('ll', 77),\n",
      " ('then', 77),\n",
      " ('come', 76),\n",
      " ('your', 74),\n",
      " ('so', 72),\n",
      " ('are', 70),\n",
      " ('do', 67),\n",
      " ('thy', 66),\n",
      " ('see', 60),\n",
      " ('hell', 58),\n",
      " ('no', 54),\n",
      " ('on', 54),\n",
      " ('or', 51),\n",
      " ('may', 50),\n",
      " ('our', 48),\n",
      " ('soul', 48),\n",
      " ('if', 47),\n",
      " ('from', 46),\n",
      " ('an', 45),\n",
      " ('at', 44),\n",
      " ('mephistophilis', 44),\n",
      " ('by', 44),\n",
      " ('these', 42),\n",
      " ('let', 42),\n",
      " ('us', 42),\n",
      " ('tell', 41),\n",
      " ('am', 41),\n",
      " ('ay', 40),\n",
      " ('art', 39),\n",
      " ('how', 38),\n",
      " ('was', 38),\n",
      " ('they', 38),\n",
      " ('here', 37),\n",
      " ('sir', 36),\n",
      " ('them', 35),\n",
      " ('into', 35),\n",
      " ('make', 35),\n",
      " ('there', 34),\n",
      " ('go', 33),\n",
      " ('heaven', 33),\n",
      " ('lucifer', 32),\n",
      " ('where', 32),\n",
      " ('world', 32),\n",
      " ('lord', 31),\n",
      " ('hath', 30),\n",
      " ('doctor', 30),\n",
      " ('god', 30),\n",
      " ('why', 30),\n",
      " ('horse', 30),\n",
      " ('would', 29),\n",
      " ('their', 29),\n",
      " ('had', 29),\n",
      " ('must', 29),\n",
      " ('some', 29),\n",
      " ('can', 28),\n",
      " ('take', 28),\n",
      " ('such', 28),\n",
      " ('devil', 28),\n",
      " ('one', 27),\n",
      " ('again', 27),\n",
      " ('more', 27),\n",
      " ('good', 27),\n",
      " ('upon', 27),\n",
      " ('emperor', 26)]\n",
      "\n",
      "Most common John Carter words:\n",
      "[('the', 4530),\n",
      " ('of', 2527),\n",
      " ('and', 2287),\n",
      " ('i', 1877),\n",
      " ('to', 1668),\n",
      " ('a', 1259),\n",
      " ('my', 951),\n",
      " ('in', 935),\n",
      " ('was', 822),\n",
      " ('that', 759),\n",
      " ('as', 725),\n",
      " ('me', 669),\n",
      " ('had', 659),\n",
      " ('with', 563),\n",
      " ('for', 526),\n",
      " ('it', 491),\n",
      " ('but', 436),\n",
      " ('which', 429),\n",
      " ('upon', 428),\n",
      " ('from', 419),\n",
      " ('his', 417),\n",
      " ('he', 381),\n",
      " ('her', 375),\n",
      " ('not', 374),\n",
      " ('you', 365),\n",
      " ('were', 337),\n",
      " ('at', 329),\n",
      " ('we', 317),\n",
      " ('they', 306),\n",
      " ('she', 293),\n",
      " ('by', 291),\n",
      " ('have', 274),\n",
      " ('their', 264),\n",
      " ('is', 261),\n",
      " ('on', 254),\n",
      " ('one', 254),\n",
      " ('this', 224),\n",
      " ('be', 216),\n",
      " ('would', 213),\n",
      " ('could', 208),\n",
      " ('so', 202),\n",
      " ('an', 197),\n",
      " ('all', 195),\n",
      " ('them', 193),\n",
      " ('him', 180),\n",
      " ('or', 176),\n",
      " ('thoris', 172),\n",
      " ('dejah', 172),\n",
      " ('than', 170),\n",
      " ('are', 170),\n",
      " ('no', 169),\n",
      " ('great', 161),\n",
      " ('been', 160),\n",
      " ('our', 158),\n",
      " ('before', 146),\n",
      " ('there', 144),\n",
      " ('then', 143),\n",
      " ('into', 140),\n",
      " ('other', 133),\n",
      " ('when', 131),\n",
      " ('who', 128),\n",
      " ('us', 128),\n",
      " ('your', 127),\n",
      " ('only', 121),\n",
      " ('toward', 121),\n",
      " ('sola', 121),\n",
      " ('warriors', 117),\n",
      " ('little', 117),\n",
      " ('did', 114),\n",
      " ('martian', 110),\n",
      " ('some', 107),\n",
      " ('helium', 107),\n",
      " ('out', 107),\n",
      " ('green', 105),\n",
      " ('two', 102),\n",
      " ('men', 100),\n",
      " ('these', 99),\n",
      " ('now', 98),\n",
      " ('about', 97),\n",
      " ('first', 97),\n",
      " ('s', 95),\n",
      " ('tarkas', 94),\n",
      " ('tars', 94),\n",
      " ('city', 92),\n",
      " ('after', 91),\n",
      " ('through', 91),\n",
      " ('what', 90),\n",
      " ('time', 89),\n",
      " ('feet', 88),\n",
      " ('more', 88),\n",
      " ('do', 87),\n",
      " ('where', 86),\n",
      " ('up', 85),\n",
      " ('man', 84),\n",
      " ('over', 81),\n",
      " ('until', 81),\n",
      " ('without', 80),\n",
      " ('down', 78),\n",
      " ('barsoom', 77),\n",
      " ('long', 76)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "# construct the counters\n",
    "counts_hamlet = Counter(hamlet)\n",
    "counts_faustus = Counter(faustus)\n",
    "counts_mars = Counter(mars)\n",
    "\n",
    "# we have to split lines now because pprint cannot take multiple arguments like print\n",
    "print(\"Most common Hamlet words:\")\n",
    "pprint(Counter.most_common(counts_hamlet, 100))\n",
    "print()\n",
    "print(\"Most common Faustus words:\")\n",
    "pprint(Counter.most_common(counts_faustus, 100))\n",
    "print()\n",
    "print(\"Most common John Carter words:\")\n",
    "pprint(Counter.most_common(counts_mars, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "What is the difference between the following two pieces of code?\n",
    "How do they differ in their output, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(hamlet[:50])\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count = Counter(hamlet)\n",
    "print(Counter.most_common(hamlet, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*put your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A problem\n",
    "\n",
    "If you look at the lists of 100 most common words for each text, you'll notice that they are fairly similar.\n",
    "For instance, all of them have *a*, *the*, and *to* among the most frequent ones.\n",
    "That's not a peculiarity of these few texts, it's a general property of English texts.\n",
    "This is because of **Zipf's law**: ranking words by their frequency, the n-th word will have a relative frequency of 1/n.\n",
    "So the most common word is twice as frequent as the second most common one, three times more frequent than the third most common one, and so on.\n",
    "As a result, a handful of words make up over 50% of all words in a text.\n",
    "\n",
    "![The Zipf dinosaur](./media/zipfgraph_dinosaur.jpeg)\n",
    "![Zipf distribution for English](./media/zipfgraph_english.png)\n",
    "\n",
    "And there is precious little variation between English texts with respect to which words are at the top.\n",
    "These common but uninformative words are called **stop words**.\n",
    "If we want to find any interesting differences between *Hamlet*, *Doctor Faustus*, and *Princess of Mars*, we have to filter out all these stop words.\n",
    "More on that next time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bullet point summary\n",
    "\n",
    "- **Getting files**\n",
    "    - `urllib.urlrequest.urlretrieve(url, filename)` is used to download and save a file.\n",
    "- **Manipulating lists**\n",
    "    - Slices allow you to extract a continuous chunk of a list.\n",
    "      The notation is `some_list[start_index:end_index]`.\n",
    "      For example, `[\"John\", \"Mary\", \"Sue\"][1:3]` is `[\"Mary\", \"Sue\"]`.\n",
    "    - In slices, start and end can be omitted.\n",
    "    ```python\n",
    "    [\"John\", \"Mary\", \"Sue\"][:2] == [\"John\", \"Mary\"]\n",
    "    [\"John\", \"Mary\", \"Sue\"][2:] == [\"Sue\"]\n",
    "    [\"John\", \"Mary\", \"Sue\"][:] == [\"John\", \"Mary\", \"Sue\"]\n",
    "     ```\n",
    "- **Loading libraries**\n",
    "    - When loading only a part of a library, you can use `from libraryX import partY` instead of `import libraryX`.\n",
    "      Then you can simple write `partY` in your code instead of `libraryX.partY`.\n",
    "- **Counters**\n",
    "    - Counters count the number of tokens for each type in a list.\n",
    "    - Load them with `from collections import Counter`.\n",
    "    - Use `Counter.most_common(your_counter, n)` to get the `n` most common words in the counter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
