{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional uses for `for`-loops\n",
    "\n",
    "We now have a function to calculate the average number of tokens per word type in a text.\n",
    "This allows us to estimate how often an author reuses words in the text.\n",
    "But it would still be nice to get a few other metrics, such as\n",
    "\n",
    "1. the frequencies of word types rather than their total counts (this makes it easier to compare different texts since 50 mentions of \"buletic\" in a 1000-page novel doesn't have the same weight as 50 mentions in a 1000-word essay),\n",
    "1. the average word length.\n",
    "\n",
    "Before we continue, though, we once again have to run all the relevant code to get counts for our three texts *Hamlet*, *Dr. Faustus*, and *Princess of Mars*.\n",
    "As before, run the cell below to make the appropriate counters available under the variable names `hamlet`, `faustus`, and `mars`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run wordcounts.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating frequencies\n",
    "\n",
    "The frequency of a word indicates how many percent of a text are taken up by its tokens.\n",
    "For example, if a word type has 6 tokens in a text of 1000 words, then its frequency is $\\frac{6}{1000} = 0.006 = 0.6\\%$.\n",
    "So we get the frequency of a word *w* by dividing the count of *w* by the total number of tokens in the text.\n",
    "\n",
    "We already have many of the tools that are needed to calculate frequencies:\n",
    "\n",
    "1. a counter for each tokenized text, and\n",
    "1. `for`-loops, and\n",
    "1. the `len`-function, and\n",
    "1. the `sum`-function, and\n",
    "1. the usage of keys such as `[x]` to get the value of a specific item `x` in a counter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can recombine these techniques to define a custom function for computing word frequencies.\n",
    "\n",
    "First, we will need to determine the total number of tokens in the text.\n",
    "But we already know how to do that with `sum` and `Counter.values`.\n",
    "Once we know the total, we can calculate the frequency of a word type by dividing its number of tokens by `total`.\n",
    "Let us put the relevant code for these steps into a function that prints the frequency of every word type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def frequencies(word_counter):\n",
    "    \"\"\"print relative frequency for each word type in counter\"\"\"\n",
    "    total = sum(Counter.values(word_counter))\n",
    "    # calculate frequencies for all the words in the counter\n",
    "    for current_word in word_counter:\n",
    "        number_of_tokens = word_counter[current_word]\n",
    "        frequency = number_of_tokens / total\n",
    "        print(frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Modify the `frequencies` function so that instead of printing each word's frequency, it returns a list of all the frequencies.\n",
    "Then use the function `sum` to verify that the the sum of all word frequencies for *Hamlet* is 1.\n",
    "After all, all the words added together should make up 100% of the text, no more, no less.\n",
    "But odds are that instead you'll get a number that's very close to 1, but not exactly 1.\n",
    "Ask your TA what's up with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999578"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put your modified version of frequencies here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding frequencies to the counter\n",
    "\n",
    "The `frequency` function is still somewhat unsatisfying in that it prints the frequency of each word type.\n",
    "Printing to screen isn't very useful most of the time, in particular with tens of thousands of words.\n",
    "It would be better if we could simply replace the absolute values in the counter by frequencies.\n",
    "This is actually fairly easy.\n",
    "The `[x]` notation is not only useful for retrieving the value of an element, it also allows us to **specify** the value of an element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'a': 6, 'b': 4, 'c': 2})\n",
      "a's current value: 6\n",
      "a's new value: 0.1\n",
      "d was added with count: 10\n",
      "The new counter is: Counter({'d': 10, 'b': 4, 'c': 2, 'a': 0.1})\n"
     ]
    }
   ],
   "source": [
    "# define our test counter\n",
    "test = Counter([\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\"])\n",
    "print(test)\n",
    "\n",
    "# let's change the value of \"a\";\n",
    "# here's what it is right now\n",
    "print(\"a's current value:\", test[\"a\"])\n",
    "# and now we'll change it to 0.1\n",
    "test[\"a\"] = 0.1\n",
    "print(\"a's new value:\", test[\"a\"])\n",
    "\n",
    "# and now we add a new element \"d\" to the counter\n",
    "test[\"d\"] = 10\n",
    "print(\"d was added with count:\", test[\"d\"])\n",
    "print(\"The new counter is:\", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Now we can finalize the `frequencies` function.\n",
    "Instead of printing the frequency of `current_word`, the function should override the value of `current_word` in `word_counter` with `frequency`.\n",
    "At the end, the function returns `word_counter`.\n",
    "You can test your code in the second cell.\n",
    "The results should be `0.t` for `a`, `0.3333` for `b`, and `0.1666` for `c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change and complete the code below\n",
    "\n",
    "def frequencies(word_counter):\n",
    "    # add an updated docstring here\n",
    "    total = sum(Counter.values(word_counter))\n",
    "    for current_word in word_counter:\n",
    "        number_of_tokens = word_counter[current_word]\n",
    "        frequency = number_of_tokens / total\n",
    "        print(frequency)  # this part needs to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'a': 6, 'b': 4, 'c': 2})\n",
      "0.3333333333333333\n",
      "0.16666666666666666\n",
      "0.5\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# test your code here\n",
    "test_counts = Counter([\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\"])\n",
    "print(test_counts)\n",
    "\n",
    "test_frequency = frequencies(test_counts)\n",
    "print(test_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An unintended side-effect\n",
    "\n",
    "Let us run the test one more time, with just a minor change in the order of the `print`-statements.\n",
    "Now we first compute `test_frequency` and the print `test_counts` and `test_frequency`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "0.16666666666666666\n",
      "0.5\n",
      "Counter({'a': 6, 'b': 4, 'c': 2})\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# test your code here\n",
    "test_counts = Counter([\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\"])\n",
    "test_frequency = frequencies(test_counts)\n",
    "\n",
    "print(test_counts)\n",
    "print(test_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uhm, what's going on here?\n",
    "Why do `test_counts` and `test_frequency` look the same?\n",
    "Where did the absolute word counts go?\n",
    "\n",
    "The problem is with how we wrote the function `frequency`.\n",
    "This is a function that takes a word counter as an argument and then **overwrites** the count of each word type with its frequency.\n",
    "So if we run `frequency` over `test_counts`, all the values of `test_counts` are replaced by frequencies.\n",
    "That's not really what we want.\n",
    "Instead, we want to produce a copy of `test_counts` with frequencies while keeping the original version of `test_counts` untouched.\n",
    "We can create a copy of a counter with the function `Counter.copy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test your code here\n",
    "test_counts = Counter([\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\"])\n",
    "test_frequency = frequencies(Counter.copy(test_counts))\n",
    "\n",
    "print(test_counts)\n",
    "print(test_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we now longer run `frequencies` on `test_counts`, but a dynamically created copy of `test_counts`.\n",
    "Hence the values of `test_counts` remain unaltered, and we get different outputs for `print` at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Copy-paste your definition of the `frequencies` function into the cell below, then change it so that it always creates a copy `temp_copy` of `word_counter` at the beginning and then carries out all operations over `temp_copy` instead of `word_counter`.\n",
    "Then run the code in the next cell to verify that your new definition of `frequencies` works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy-paste your code for frequencies here, then modify it as described"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test your code here\n",
    "test_counts = Counter([\"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\", \"c\", \"c\"])\n",
    "test_frequency = frequencies(test_counts)\n",
    "\n",
    "print(test_counts)\n",
    "print(test_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating average word length\n",
    "\n",
    "Let us turn to average word length next.\n",
    "Rather than explain at length how it works, I already created a working solution for you.\n",
    "Your job is just to figure out what it does.\n",
    "I will tell you that much, though: `*` is multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_word_length(word_counter):\n",
    "    \"\"\"average word length for counter\"\"\"\n",
    "    total_number = sum(Counter.values(word_counter))\n",
    "    total_length = 0\n",
    "    for word in word_counter:\n",
    "        total_length = total_length + (word_counter[word] * len(word))\n",
    "    return total_length / total_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Carefully read the code above.\n",
    "Then describe what this function does.\n",
    "Pay particular attention to the `for`-loop and the use of `len`, and explain why `len(word)` must be multiplied with `word_counter[word]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*put your explanation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what happens when we run this function on our three texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.058128662261564\n",
      "4.074778200253485\n",
      "4.345717874600845\n"
     ]
    }
   ],
   "source": [
    "for text in [hamlet, faustus, mars]:\n",
    "    print(avg_word_length(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, that's surprisingly close together.\n",
    "One would expect a novel like *Princess of Mars* to have longer words than a play like *Hamlet* or *Dr. Faustus*, simply because the latter have to fit a specific meter.\n",
    "\n",
    "But wait a second!\n",
    "*Zipf's law* tells us that the majority of texts is made up of a few very high-frequency words, called *stop words*.\n",
    "So if those stop words are very short, then that will drastically lower average word length.\n",
    "And that is indeed the case, as you can probably tell from eyeballing [this list of stopwords](https://raw.githubusercontent.com/Alir3z4/stop-words/master/english.txt).\n",
    "We can even use Python to see this point more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n",
      "\n",
      "Average word length: 4.482758620689655\n"
     ]
    }
   ],
   "source": [
    "# download list of stop words\n",
    "import urllib.request\n",
    "url = \"https://raw.githubusercontent.com/Alir3z4/stop-words/master/english.txt\"\n",
    "urllib.request.urlretrieve(url, \"stopwords.txt\")\n",
    "\n",
    "# read it in as a string\n",
    "with open(\"stopwords.txt\", \"r\", encoding=\"utf-8\") as stopwords_file:\n",
    "    stopwords = stopwords_file.read()\n",
    "\n",
    "# since each word is on its own line,\n",
    "# we can convert the string to a list of words by\n",
    "# matching everything except newlines (\\n)\n",
    "stopwords = re.findall(r\"[^\\n]+\", stopwords)\n",
    "\n",
    "# and here is what we have\n",
    "print(stopwords)\n",
    "\n",
    "# and this is the average word length\n",
    "print(\"\\nAverage word length:\", avg_word_length(Counter(stopwords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the average word length for all three texts is very close to the average word length of English stop words.\n",
    "So there is a good chance that we will get a much more pronounced difference in average word length between the three texts if we ignore stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stopwords\n",
    "\n",
    "Our goal at this point is clear: We have to get rid of those pesky stopwords.\n",
    "As you might recall from the previous unit, this is actually fairly easy with a `for`-loop.\n",
    "So what are you waiting for, get hacking!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Use what you've learned so far to filter out all the elements of `stopwords` before calculating average word length.\n",
    "Yes, this is deliberately phrased very vaguely.\n",
    "There's multiple routes you can take, and it is up to you to decide which one is the most appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "You might have noticed a minor problem.\n",
    "The counters are built from a tokenized list, and our tokenization function treats words like *who's* as two tokens *who* and *s*.\n",
    "But our list of stop words instead treats *who* and *who's* as stop words, but not *s* because it assumes that *who's* is never split into *who* and *s*.\n",
    "As a result, your solution will filter out *who* when calculating average word length, but not *s*.\n",
    "\n",
    "Copy-paste your previous solution into the cell below, then fix it so that *s* is also filtered out correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy-paste the code here, then modify it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "Has the removal of stop words led to a greater difference in word length between the texts?\n",
    "Do we see a more pronounced difference between plays and novels now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*put your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "\n",
    "This unit hasn't introduced a lot of new concepts, instead you just got to see how the tools we have encountered so far can be used to accomplish a variety of things.\n",
    "In particular `for`-loops have quickly become indispensable.\n",
    "They really are one of Python's most important and versatile tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises.**\n",
    "We can even use `for`-loops to implement a very simple spellchecker.\n",
    "[This textfile](https://raw.githubusercontent.com/dwyl/english-words/master/words.txt) lists almost all words of English (it has over 500,000 entries).\n",
    "It is similar to our list of stopwords in that it contains one word per line.\n",
    "\n",
    "The code below downloads the file for you and reads it in as a string.\n",
    "Here is your task:\n",
    "\n",
    "1.  Tokenize the string to get a list of correctly spelled English words.\n",
    "1.  Write a function `spellcheck` such that\n",
    "    1. The function takes as its argument a string and a list of words, the dictionary.\n",
    "    1. The function tokenizes the string (words like *who's* should be tokenized as *who's*, so you'll have to modify our standard tokenization function).\n",
    "    1. It then checks every token in the string and returns a list of all misspelled words (types, not tokens!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download the file\n",
    "url = \"https://raw.githubusercontent.com/dwyl/english-words/master/words.txt\"\n",
    "urllib.request.urlretrieve(url, \"words.txt\")\n",
    "\n",
    "with open(\"words.txt\", \"r\", encoding=\"utf-8\") as dict_file:\n",
    "    dict_string = dict_file.read()\n",
    "\n",
    "# Step 1: tokenize dict_string; don't forget that who's should be treated as one word, not two\n",
    "# dictionary = for you to do\n",
    "\n",
    "# Step 2: define custom function\n",
    "# def spellcheck(string, wordlist):\n",
    "    # some mystery happens here\n",
    "\n",
    "# let's test the code\n",
    "examples = [\"My neighbour is to tried for work.\",\n",
    "            \"I am teh world's gr8test typist\",\n",
    "            \"U don't look 2 bed\",\n",
    "            \"Their are titilating oportunitys here.\"]\n",
    "for example in examples:\n",
    "    print(example, \"contains the following errors:\", spellcheck(example, dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints:*\n",
    "If you're stuck with the exercise, highlight the text below to read some tips.\n",
    "\n",
    "<span style=\"color:#000000;background-color:#000000;\">\n",
    "For the tokenization function, remember that \\w+ matches sequences of word characters.\n",
    "But you can combine \\w with the [...] notation to define alternatives.\n",
    "So [xyz\\w]+ matches sequences that consist of word characters and/or instances of x, y, and z.\n",
    "Use this to broaden the match from word characters to word characters and apostrophes.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bullet point summary\n",
    "\n",
    "- Nothing new here, just using familiar tools in creative ways.\n",
    "  Like language, programming is about combining familiar things to create something new."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
